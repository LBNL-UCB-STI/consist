{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3aeab6bb383f65",
   "metadata": {},
   "source": [
    "# Transportation Equilibrium Model: Deep Provenance Chains\n",
    "\n",
    "This notebook demonstrates how Consist tracks provenance through an **iterative equilibrium model**—a common pattern in transportation, economics, and agent-based simulation where outputs feed back as inputs until the system converges.\n",
    "\n",
    "## The Model\n",
    "\n",
    "We simulate morning commute mode choice in a stylized 5-zone linear city:\n",
    "\n",
    "```\n",
    "Zone 1 ←→ Zone 2 ←→ Zone 3 ←→ Zone 4 ←→ Zone 5\n",
    "(Low)     (Med)     (High/CBD)  (Med)     (Low)\n",
    "```\n",
    "\n",
    "**Feedback loop:**\n",
    "1. **Logsums**: Compute accessibility from current travel times\n",
    "2. **Trip Distribution**: Workers choose job locations based on accessibility\n",
    "3. **Mode Choice**: Each commuter chooses car, transit, or walk\n",
    "4. **Assignment**: Car trips create congestion\n",
    "5. **Skim Update**: Congestion slows travel times → back to step 1\n",
    "\n",
    "The model iterates until mode shares stabilize.\n",
    "\n",
    "## Provenance Value\n",
    "\n",
    "This structure lets us answer questions like:\n",
    "- \"Which iteration's skims were used to produce this trip table?\"\n",
    "- \"If I change parking costs, which steps need to re-run?\"\n",
    "- \"Can I resume from iteration 7 with a tighter convergence threshold?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb92e76e1e4227e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:42:44.364361Z",
     "start_time": "2025-12-26T17:42:44.349415Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for candidate in (start, *start.parents):\n",
    "        if (candidate / \"pyproject.toml\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Could not locate repo root (missing pyproject.toml)\")\n",
    "\n",
    "\n",
    "REPO_ROOT = _find_repo_root(Path.cwd())\n",
    "EXAMPLES_DIR = REPO_ROOT / \"examples\"\n",
    "EXAMPLES_SRC = EXAMPLES_DIR / \"src\"\n",
    "\n",
    "for path in (REPO_ROOT, EXAMPLES_SRC):\n",
    "    if str(path) not in sys.path:\n",
    "        sys.path.insert(0, str(path))"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "f10d240ad42d3a85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:42:44.787124Z",
     "start_time": "2025-12-26T17:42:44.372215Z"
    }
   },
   "source": [
    "import uuid\n",
    "from dataclasses import asdict, replace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import consist\n",
    "from consist import Tracker\n",
    "\n",
    "from travel_demand_functions import (\n",
    "    AssignmentParams,\n",
    "    DestinationChoiceParams,\n",
    "    ModeChoiceParams,\n",
    "    TravelDemandScenarioConfig,\n",
    "    ZoneParams,\n",
    "    apply_congestion,\n",
    "    apply_mode_choice,\n",
    "    compute_mode_shares,\n",
    "    compute_mode_utilities,\n",
    "    compute_od_logsums,\n",
    "    compute_od_volumes,\n",
    "    create_skims_dataset,\n",
    "    distribute_trips,\n",
    "    generate_distances,\n",
    "    generate_population,\n",
    "    generate_zones,\n",
    "    save_skims,\n",
    "    summarize_iteration,\n",
    ")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "c76245405f23eacd",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We initialize the tracker and import our model functions. Each run gets a unique session ID so we can compare multiple runs in the same database."
   ]
  },
  {
   "cell_type": "code",
   "id": "440e59f91d965d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:42:44.875005Z",
     "start_time": "2025-12-26T17:42:44.787677Z"
    }
   },
   "source": [
    "EXAMPLES_DIR = REPO_ROOT / \"examples\"\n",
    "RUN_DIR = EXAMPLES_DIR / \"runs\" / \"travel_demand_demo\"\n",
    "SESSION_ID = uuid.uuid4().hex[:8]\n",
    "DB_PATH = RUN_DIR / f\"travel_demand_demo_{SESSION_ID}.duckdb\"\n",
    "\n",
    "tracker = Tracker(run_dir=RUN_DIR, db_path=DB_PATH, hashing_strategy=\"fast\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to relax run.parent_run_id FK: (_duckdb.NotImplementedException) Not implemented Error: No support for that ALTER TABLE option yet!\n",
      "[SQL: ALTER TABLE run DROP CONSTRAINT IF EXISTS fk_run_parent]\n",
      "(Background on this error at: https://sqlalche.me/e/20/tw8g)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "44d689b80c6e9710",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "\n",
    "The model has four parameter groups:\n",
    "\n",
    "| Parameter Group           | Controls                                                     |\n",
    "|---------------------------|--------------------------------------------------------------|\n",
    "| `ZoneParams`              | City layout: population, jobs, parking costs, transit access |\n",
    "| `ModeChoiceParams`        | Utility coefficients, speeds, costs                          |\n",
    "| `DestinationChoiceParams` | How accessibility affects job location choice                |\n",
    "| `AssignmentParams`        | BPR congestion function parameters                           |\n",
    "\n",
    "**ZoneParams** defines the city structure. The central zone (Zone 3) has the most jobs and highest parking costs, mimicking a downtown CBD. Outer zones are residential with cheaper or free parking.\n",
    "\n",
    "**ModeChoiceParams** sets the coefficients for a standard multinomial logit mode choice model. `beta_cost` and `beta_time` control sensitivity to travel cost and time; the ASCs (alternative-specific constants) capture baseline preferences for transit and walking relative to driving.\n",
    "\n",
    "**DestinationChoiceParams** governs how workers choose job locations. `beta_access` weights the logsum (a measure of how easy it is to reach a zone by any mode), while `beta_size` weights employment size.\n",
    "\n",
    "**AssignmentParams** controls the BPR (Bureau of Public Roads) volume-delay function that converts traffic volumes into congested travel times.\n",
    "\n",
    "We also set two equilibrium parameters:\n",
    "- `SKIM_PERTURBATION`: Initial congestion multiplier (starts the system away from equilibrium so we can watch it converge)\n",
    "- `DESTINATION_UPDATE_SHARE`: Damping factor for stability (blend new destination choices with previous iteration to prevent oscillation)"
   ]
  },
  {
   "cell_type": "code",
   "id": "3047e99cf95e8869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:42:44.886847Z",
     "start_time": "2025-12-26T17:42:44.881585Z"
    }
   },
   "source": [
    "zone_params = ZoneParams()\n",
    "mode_params = ModeChoiceParams()\n",
    "dest_params = DestinationChoiceParams()\n",
    "assignment_params = AssignmentParams()\n",
    "\n",
    "DEFAULT_SEED = 0\n",
    "\n",
    "base_config = TravelDemandScenarioConfig(\n",
    "    n_iterations=10,\n",
    "    seed=DEFAULT_SEED,\n",
    "    zone_params=zone_params,\n",
    "    mode_params=mode_params,\n",
    "    dest_params=dest_params,\n",
    "    assignment_params=assignment_params,\n",
    ")\n",
    "\n",
    "SCENARIO_NAME = \"travel_demand_demo\"\n",
    "\n",
    "SKIM_PERTURBATION = 2.0\n",
    "DESTINATION_UPDATE_SHARE = 0.4"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "7a2e0f5b62b8f193",
   "metadata": {},
   "source": [
    "## Baseline Scenario\n",
    "\n",
    "We run the equilibrium loop, tracking each step's inputs and outputs. The coupler passes artifacts between steps within the scenario—when we update `skims` after traffic simulation, the next iteration's logsum calculation automatically picks up the congested version.\n",
    "\n",
    "### Step Structure per Iteration\n",
    "\n",
    "```\n",
    "┌─────────────┐\n",
    "│    init     │ (iteration 0 only)\n",
    "└──────┬──────┘\n",
    "       │ skims, zones, population\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│   logsums   │◄─── skims, zones\n",
    "└──────┬──────┘\n",
    "       │ logsums\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ trip_dist   │◄─── logsums, zones, population\n",
    "└──────┬──────┘\n",
    "       │ trips\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ utilities   │◄─── trips, skims, zones\n",
    "└──────┬──────┘\n",
    "       │ utilities\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ mode_choice │◄─── utilities, (prev trips_with_modes)\n",
    "└──────┬──────┘\n",
    "       │ trips_with_modes\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ assignment  │◄─── trips_with_modes\n",
    "└──────┬──────┘\n",
    "       │ volumes\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ traffic_sim │◄─── volumes, skims\n",
    "└──────┬──────┘\n",
    "       │ updated skims ──► next iteration\n",
    "       ▼\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "4e89891d25158363",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:42:44.901462Z",
     "start_time": "2025-12-26T17:42:44.887215Z"
    }
   },
   "source": [
    "def run_scenario(scenario_config, scenario_run_id):\n",
    "    mode_shares = {}\n",
    "    summaries = {}\n",
    "    pmt_totals = {}\n",
    "\n",
    "    zone_params = scenario_config.zone_params\n",
    "    mode_params = scenario_config.mode_params\n",
    "    dest_params = scenario_config.dest_params\n",
    "    assignment_params = scenario_config.assignment_params\n",
    "    seed = scenario_config.seed\n",
    "\n",
    "    with tracker.scenario(\n",
    "        scenario_run_id,\n",
    "        config={\n",
    "            **asdict(scenario_config),\n",
    "            \"scenario_name\": SCENARIO_NAME,\n",
    "        },\n",
    "        facet_from=[\"n_iterations\"],\n",
    "        tags=[\"examples\", \"simulation\", \"travel_demand\"],\n",
    "    ) as scenario:\n",
    "        scenario_output_dir = RUN_DIR / scenario.run_id\n",
    "        scenario_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        input_dir = scenario_output_dir / \"travel_demand_input\"\n",
    "        input_dir.mkdir(parents=True, exist_ok=True)\n",
    "        cache_validation = \"lazy\"  # Skip output checks on cache hits for speed; use 'eager' to validate files.\n",
    "        cache_hydration = \"inputs-missing\"  # Copy cached inputs into the new run_dir on cache misses.\n",
    "\n",
    "        def _init():\n",
    "            zones = generate_zones(zone_params)\n",
    "            population = generate_population(zones)\n",
    "            distances = generate_distances(zone_params)\n",
    "\n",
    "            skims = create_skims_dataset(zones, distances, mode_params)\n",
    "            skims[\"time_car_mins\"] *= SKIM_PERTURBATION\n",
    "\n",
    "            input_skims_path = input_dir / \"skims_init.zarr\"\n",
    "            input_persons_path = input_dir / \"population_init.parquet\"\n",
    "            input_zones_path = input_dir / \"zones.parquet\"\n",
    "\n",
    "            save_skims(skims, input_skims_path)\n",
    "\n",
    "            consist.log_artifact(input_skims_path, key=\"skims\", direction=\"output\")\n",
    "            consist.log_dataframe(\n",
    "                population,\n",
    "                key=\"persons\",\n",
    "                direction=\"output\",\n",
    "                path=input_persons_path,\n",
    "            )\n",
    "            consist.log_dataframe(\n",
    "                zones, key=\"zones\", direction=\"output\", path=input_zones_path\n",
    "            )\n",
    "\n",
    "        scenario.run_step(\n",
    "            name=\"init\",\n",
    "            fn=_init,\n",
    "            config=asdict(mode_params)\n",
    "            | asdict(zone_params)\n",
    "            | {\"skim_perturbation\": SKIM_PERTURBATION},\n",
    "            facet_from=[\"skim_perturbation\"],\n",
    "            outputs=[\"skims\", \"persons\", \"zones\"],\n",
    "        )\n",
    "\n",
    "        for i in tqdm(range(scenario_config.n_iterations)):\n",
    "            def _logsums():\n",
    "                output_dir = scenario_output_dir / f\"iteration_{i}\"\n",
    "                output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                skims = consist.load(scenario.coupler.require(\"skims\"))\n",
    "                zones = consist.load(scenario.coupler.require(\"zones\"))\n",
    "                logsums = compute_od_logsums(skims, zones, mode_params)\n",
    "                consist.log_dataframe(\n",
    "                    logsums.to_dataframe().reset_index(),\n",
    "                    key=\"logsums\",\n",
    "                    path=output_dir / \"logsums.parquet\",\n",
    "                )\n",
    "\n",
    "            scenario.run_step(\n",
    "                name=\"logsums\",\n",
    "                fn=_logsums,\n",
    "                run_id=f\"{scenario.run_id}_logsums_{i}\",\n",
    "                config=asdict(mode_params),\n",
    "                input_keys=[\"skims\", \"zones\"],\n",
    "                facet_from=[\n",
    "                    \"beta_cost\",\n",
    "                    \"beta_time\",\n",
    "                    \"asc_walk\",\n",
    "                    \"asc_transit\",\n",
    "                    \"fuel_cost_per_mile\",\n",
    "                    \"transit_fare\",\n",
    "                ],\n",
    "                validate_cached_outputs=cache_validation,\n",
    "                cache_hydration=cache_hydration,\n",
    "                outputs=[\"logsums\"],\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            def _trip_distribution():\n",
    "                output_dir = scenario_output_dir / f\"iteration_{i}\"\n",
    "                output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                zones = consist.load(scenario.coupler.require(\"zones\"))\n",
    "                population = consist.load(scenario.coupler.require(\"persons\"))\n",
    "                prev_trips_art = scenario.coupler.get(\"trips\")\n",
    "                prev_trips = consist.load(prev_trips_art) if prev_trips_art else None\n",
    "                logsums_df = consist.load(scenario.coupler.require(\"logsums\"))\n",
    "                if (\n",
    "                    \"origin\" not in logsums_df.columns\n",
    "                    or \"destination\" not in logsums_df.columns\n",
    "                ):\n",
    "                    logsums_df = logsums_df.reset_index()\n",
    "                logsums = logsums_df.set_index([\"origin\", \"destination\"])[\n",
    "                    \"logsum\"\n",
    "                ].to_xarray()\n",
    "                trips = distribute_trips(\n",
    "                    population,\n",
    "                    zones,\n",
    "                    logsums,\n",
    "                    dest_params,\n",
    "                    seed=seed + i,\n",
    "                    prev_trips=prev_trips,\n",
    "                    update_share=DESTINATION_UPDATE_SHARE,\n",
    "                )\n",
    "                consist.log_dataframe(\n",
    "                    trips, key=\"trips\", path=output_dir / \"trips.parquet\"\n",
    "                )\n",
    "\n",
    "            scenario.run_step(\n",
    "                name=\"trip_distribution\",\n",
    "                fn=_trip_distribution,\n",
    "                run_id=f\"{scenario.run_id}_trip_distribution_{i}\",\n",
    "                config={\n",
    "                    **asdict(dest_params),\n",
    "                    \"update_share\": DESTINATION_UPDATE_SHARE,\n",
    "                },\n",
    "                input_keys=[\"skims\", \"zones\", \"persons\", \"logsums\"],\n",
    "                optional_input_keys=[\"trips\"],\n",
    "                facet_from=[\"beta_size\", \"beta_access\", \"update_share\"],\n",
    "                outputs=[\"trips\"],\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            def _calculate_utilities():\n",
    "                output_dir = scenario_output_dir / f\"iteration_{i}\"\n",
    "                output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                trips = consist.load(scenario.coupler.require(\"trips\"))\n",
    "                skims = consist.load(scenario.coupler.require(\"skims\"))\n",
    "                zones = consist.load(scenario.coupler.require(\"zones\"))\n",
    "                utilities = compute_mode_utilities(trips, skims, zones, mode_params)\n",
    "                consist.log_dataframe(\n",
    "                    utilities, key=\"utilities\", path=(output_dir / \"utilities.parquet\")\n",
    "                )\n",
    "\n",
    "            scenario.run_step(\n",
    "                name=\"calculate_utilities\",\n",
    "                fn=_calculate_utilities,\n",
    "                run_id=f\"{scenario.run_id}_utilities_{i}\",\n",
    "                config=asdict(mode_params),\n",
    "                input_keys=[\"trips\", \"skims\", \"zones\"],\n",
    "                facet_from=[\n",
    "                    \"beta_cost\",\n",
    "                    \"beta_time\",\n",
    "                    \"asc_walk\",\n",
    "                    \"asc_transit\",\n",
    "                ],\n",
    "                validate_cached_outputs=cache_validation,\n",
    "                cache_hydration=cache_hydration,\n",
    "                outputs=[\"utilities\"],\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            def _mode_choice():\n",
    "                output_dir = scenario_output_dir / f\"iteration_{i}\"\n",
    "                output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                utilities = consist.load(scenario.coupler.require(\"utilities\"))\n",
    "                trips_with_modes = apply_mode_choice(utilities, seed=seed + i)\n",
    "                consist.log_dataframe(\n",
    "                    trips_with_modes,\n",
    "                    key=\"trips_with_modes\",\n",
    "                    path=output_dir / \"trips_with_modes.parquet\",\n",
    "                )\n",
    "\n",
    "            scenario.run_step(\n",
    "                name=\"mode_choice\",\n",
    "                fn=_mode_choice,\n",
    "                run_id=f\"{scenario.run_id}_mode_choice_{i}\",\n",
    "                config={\"seed\": seed},\n",
    "                input_keys=[\"trips\", \"utilities\"],\n",
    "                outputs=[\"trips_with_modes\"],\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            def _assignment():\n",
    "                output_dir = scenario_output_dir / f\"iteration_{i}\"\n",
    "                output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                trips_with_modes = consist.load(\n",
    "                    scenario.coupler.require(\"trips_with_modes\")\n",
    "                )\n",
    "                volumes = compute_od_volumes(trips_with_modes)\n",
    "                consist.log_dataframe(\n",
    "                    volumes, key=\"volumes\", path=(output_dir / \"volumes.parquet\")\n",
    "                )\n",
    "\n",
    "            scenario.run_step(\n",
    "                name=\"assignment\",\n",
    "                fn=_assignment,\n",
    "                run_id=f\"{scenario.run_id}_assignment_{i}\",\n",
    "                input_keys=[\"trips_with_modes\"],\n",
    "                outputs=[\"volumes\"],\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            def _traffic_simulation():\n",
    "                output_dir = scenario_output_dir / f\"iteration_{i}\"\n",
    "                output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                volumes = consist.load(scenario.coupler.require(\"volumes\"))\n",
    "                skims = consist.load(scenario.coupler.require(\"skims\"))\n",
    "                skims = apply_congestion(skims, volumes, assignment_params)\n",
    "                output_skims_path = output_dir / \"skims_out.zarr\"\n",
    "                save_skims(skims, output_skims_path)\n",
    "                consist.log_artifact(output_skims_path, key=\"skims\", direction=\"output\")\n",
    "\n",
    "            scenario.run_step(\n",
    "                name=\"traffic_simulation\",\n",
    "                fn=_traffic_simulation,\n",
    "                run_id=f\"{scenario.run_id}_traffic_simulation_{i}\",\n",
    "                config=asdict(assignment_params),\n",
    "                input_keys=[\"volumes\", \"skims\"],\n",
    "                facet_from=[\"bpr_alpha\", \"bpr_beta\", \"base_capacity\"],\n",
    "                outputs=[\"skims\"],\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            trips_with_modes = consist.load(\n",
    "                scenario.coupler.require(\"trips_with_modes\")\n",
    "            )\n",
    "            shares = compute_mode_shares(trips_with_modes)\n",
    "            mode_shares[i] = pd.Series(shares)\n",
    "            distance_by_mode = trips_with_modes.groupby(\"mode\")[\"distance_miles\"].sum()\n",
    "            pmt_totals[i] = distance_by_mode.sort_index()\n",
    "            summaries[i] = summarize_iteration(i, trips_with_modes, shares, 0, False)\n",
    "\n",
    "        def _summaries():\n",
    "            summary_dir = scenario_output_dir / \"summary\"\n",
    "            summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            mode_shares_df = (\n",
    "                pd.DataFrame.from_dict(mode_shares, orient=\"index\")\n",
    "                .sort_index()\n",
    "                .rename_axis(\"iteration\")\n",
    "                .reset_index()\n",
    "            )\n",
    "            summaries_df = (\n",
    "                pd.DataFrame.from_dict(summaries, orient=\"index\")\n",
    "                .sort_values(\"iteration\")\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            pmt_totals_df = (\n",
    "                pd.DataFrame.from_dict(pmt_totals, orient=\"index\")\n",
    "                .sort_index()\n",
    "                .rename_axis(\"iteration\")\n",
    "                .reset_index()\n",
    "            )\n",
    "\n",
    "            mode_shares_path = summary_dir / \"mode_shares.csv\"\n",
    "            summaries_path = summary_dir / \"iteration_summaries.csv\"\n",
    "            pmt_totals_path = summary_dir / \"pmt_totals.csv\"\n",
    "            mode_shares_df.to_csv(mode_shares_path, index=False)\n",
    "            summaries_df.to_csv(summaries_path, index=False)\n",
    "            pmt_totals_df.to_csv(pmt_totals_path, index=False)\n",
    "\n",
    "            shares_long = mode_shares_df.melt(\n",
    "                id_vars=\"iteration\", var_name=\"mode\", value_name=\"share\"\n",
    "            )\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            sns.lineplot(\n",
    "                data=shares_long, x=\"iteration\", y=\"share\", hue=\"mode\", marker=\"o\"\n",
    "            )\n",
    "            plt.title(\"Mode Shares by Iteration\")\n",
    "            plt.tight_layout()\n",
    "            mode_share_plot_path = summary_dir / \"mode_shares.png\"\n",
    "            plt.savefig(mode_share_plot_path)\n",
    "            plt.close()\n",
    "\n",
    "            pmt_long = pmt_totals_df.melt(\n",
    "                id_vars=\"iteration\", var_name=\"mode\", value_name=\"pmt\"\n",
    "            )\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "            sns.lineplot(\n",
    "                data=summaries_df, x=\"iteration\", y=\"vmt\", marker=\"o\", ax=axes[0]\n",
    "            )\n",
    "            axes[0].set_title(\"Vehicle Miles Traveled\")\n",
    "            sns.lineplot(\n",
    "                data=pmt_long,\n",
    "                x=\"iteration\",\n",
    "                y=\"pmt\",\n",
    "                hue=\"mode\",\n",
    "                marker=\"o\",\n",
    "                ax=axes[1],\n",
    "            )\n",
    "            axes[1].set_title(\"Person Miles Traveled by Mode\")\n",
    "            fig.tight_layout()\n",
    "            totals_plot_path = summary_dir / \"iteration_totals.png\"\n",
    "            fig.savefig(totals_plot_path)\n",
    "            plt.close(fig)\n",
    "\n",
    "            consist.log_dataframe(\n",
    "                mode_shares_df,\n",
    "                key=\"mode_shares\",\n",
    "                path=mode_shares_path,\n",
    "            )\n",
    "            consist.log_dataframe(\n",
    "                summaries_df,\n",
    "                key=\"iteration_summaries\",\n",
    "                path=summaries_path,\n",
    "            )\n",
    "            consist.log_dataframe(\n",
    "                pmt_totals_df,\n",
    "                key=\"pmt_totals\",\n",
    "                path=pmt_totals_path,\n",
    "            )\n",
    "            consist.log_artifact(\n",
    "                mode_share_plot_path,\n",
    "                key=\"mode_shares_plot\",\n",
    "                direction=\"output\",\n",
    "            )\n",
    "            consist.log_artifact(\n",
    "                totals_plot_path,\n",
    "                key=\"iteration_totals_plot\",\n",
    "                direction=\"output\",\n",
    "            )\n",
    "\n",
    "        scenario.run_step(\n",
    "            name=\"summaries\",\n",
    "            fn=_summaries,\n",
    "            input_keys=[\"trips_with_modes\"],\n",
    "            outputs=[\n",
    "                \"mode_shares\",\n",
    "                \"iteration_summaries\",\n",
    "                \"pmt_totals\",\n",
    "                \"mode_shares_plot\",\n",
    "                \"iteration_totals_plot\",\n",
    "            ],\n",
    "                validate_cached_outputs=cache_validation,\n",
    "                cache_hydration=cache_hydration,\n",
    "        )\n",
    "\n",
    "        mode_shares_df = consist.load(scenario.coupler.require(\"mode_shares\"))\n",
    "        summaries_df = consist.load(scenario.coupler.require(\"iteration_summaries\"))\n",
    "        pmt_totals_df = consist.load(scenario.coupler.require(\"pmt_totals\"))\n",
    "        mode_share_plot_path = scenario.coupler.path(\"mode_shares_plot\")\n",
    "        totals_plot_path = scenario.coupler.path(\"iteration_totals_plot\")\n",
    "\n",
    "    return {\n",
    "        \"scenario_run_id\": scenario_run_id,\n",
    "        \"mode_shares_df\": mode_shares_df,\n",
    "        \"summaries_df\": summaries_df,\n",
    "        \"pmt_totals_df\": pmt_totals_df,\n",
    "        \"mode_share_plot_path\": mode_share_plot_path,\n",
    "        \"totals_plot_path\": totals_plot_path,\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "a50e498953b5b49c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:43:10.058681Z",
     "start_time": "2025-12-26T17:42:44.902238Z"
    }
   },
   "source": [
    "base_run_id = f\"{SCENARIO_NAME}_{SESSION_ID}\"\n",
    "base_results = run_scenario(base_config, base_run_id)\n",
    "\n",
    "analysis = base_results\n",
    "\n",
    "mode_shares_df = analysis[\"mode_shares_df\"]\n",
    "summaries_df = analysis[\"summaries_df\"]\n",
    "pmt_totals_df = analysis[\"pmt_totals_df\"]\n",
    "mode_share_plot_path = analysis[\"mode_share_plot_path\"]\n",
    "totals_plot_path = analysis[\"totals_plot_path\"]\n",
    "SCENARIO_RUN_ID = analysis[\"scenario_run_id\"]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "5109f8b67e78fa3",
   "metadata": {},
   "source": [
    "## Scenario Comparison: Higher Parking Costs\n",
    "\n",
    "Now let's run a second scenario with higher CBD parking costs and compare the outcomes to",
    "the baseline run. We'll focus on final-iteration mode shares, person-miles traveled, and",
    "core summary metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fadab78dfd2d15dd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-26T17:43:10.059307Z"
    }
   },
   "source": [
    "high_parking_config = replace(\n",
    "    base_config,\n",
    "    zone_params=ZoneParams(parking_costs=(0.0, 8.0, 25.0, 8.0, 0.0)),\n",
    ")\n",
    "high_parking_run_id = f\"{SCENARIO_NAME}_{SESSION_ID}_high_parking\"\n",
    "high_parking_results = run_scenario(high_parking_config, high_parking_run_id)\n",
    "\n",
    "final_iteration = base_results[\"summaries_df\"][\"iteration\"].max()\n",
    "\n",
    "base_shares = base_results[\"mode_shares_df\"].set_index(\"iteration\").loc[final_iteration]\n",
    "hp_shares = (\n",
    "    high_parking_results[\"mode_shares_df\"].set_index(\"iteration\").loc[final_iteration]\n",
    ")\n",
    "mode_share_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"base\": base_shares,\n",
    "        \"high_parking\": hp_shares,\n",
    "    }\n",
    ")\n",
    "mode_share_comparison[\"delta\"] = (\n",
    "    mode_share_comparison[\"high_parking\"] - mode_share_comparison[\"base\"]\n",
    ")\n",
    "\n",
    "base_pmt = base_results[\"pmt_totals_df\"].set_index(\"iteration\").loc[final_iteration]\n",
    "hp_pmt = (\n",
    "    high_parking_results[\"pmt_totals_df\"].set_index(\"iteration\").loc[final_iteration]\n",
    ")\n",
    "pmt_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"base\": base_pmt,\n",
    "        \"high_parking\": hp_pmt,\n",
    "    }\n",
    ")\n",
    "pmt_comparison[\"delta\"] = pmt_comparison[\"high_parking\"] - pmt_comparison[\"base\"]\n",
    "\n",
    "summary_cols = [\"vmt\", \"total_trips\", \"car_share\", \"transit_share\", \"walk_share\"]\n",
    "base_summary = (\n",
    "    base_results[\"summaries_df\"]\n",
    "    .set_index(\"iteration\")\n",
    "    .loc[final_iteration, summary_cols]\n",
    ")\n",
    "hp_summary = (\n",
    "    high_parking_results[\"summaries_df\"]\n",
    "    .set_index(\"iteration\")\n",
    "    .loc[final_iteration, summary_cols]\n",
    ")\n",
    "summary_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"base\": base_summary,\n",
    "        \"high_parking\": hp_summary,\n",
    "    }\n",
    ")\n",
    "summary_comparison[\"delta\"] = (\n",
    "    summary_comparison[\"high_parking\"] - summary_comparison[\"base\"]\n",
    ")\n",
    "\n",
    "display(mode_share_comparison)\n",
    "display(pmt_comparison)\n",
    "display(summary_comparison)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:10<00:25,  3.62s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c21847eedc4d7ff",
   "metadata": {},
   "source": [
    "## Convergence Results\n",
    "\n",
    "Let's examine how mode shares evolved across iterations. In a well-tuned model, shares should\n",
    "stabilize as the feedback between congestion and mode choice reaches equilibrium.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "644c88fd6799ab98",
   "metadata": {},
   "source": [
    "mode_shares_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a1e813675e09be2a",
   "metadata": {},
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=str(mode_share_plot_path))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1db4e423963ede6d",
   "metadata": {},
   "source": [
    "## Incremental Computation Demo\n",
    "\n",
    "We ran the baseline scenario for 10 iterations above. Now we'll run an extended scenario for",
    "15 iterations. Since the extended run shares the same parameters for iterations 0-9, Consist",
    "should recognize those steps have already been computed and skip them—only running iterations 10",
    "through 14.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "62b98f798bf484c5",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CONSIST_CACHE_DEBUG\"] = \"1\"  # Log cache hits/misses during the incremental run.\n",
    "extended_config = replace(base_config, n_iterations=15)\n",
    "extended_run_id = f\"{SCENARIO_NAME}_{SESSION_ID}_extended\"\n",
    "extended_results = run_scenario(extended_config, extended_run_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b66742136899be3",
   "metadata": {},
   "source": [
    "# Quick cache-hit check for the extended run.\n",
    "cached_runs = [\n",
    "    run\n",
    "    for run in tracker.find_runs(parent_id=extended_results[\"scenario_run_id\"])\n",
    "    if run.meta.get(\"cache_hit\")\n",
    "]\n",
    "[(run.model_name, run.iteration, run.id) for run in cached_runs]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c3f55475b483a7d",
   "metadata": {},
   "source": [
    "As expected, all steps from iterations 0-9 were retrieved from cache. The extended run only\n",
    "computed the 5 new iterations, demonstrating how Consist enables incremental refinement of\n",
    "iterative models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86ffe6b6b5de8f",
   "metadata": {},
   "source": [
    "## Querying Provenance\n",
    "\n",
    "Now let's use Consist's query capabilities to explore the artifact lineage. We can find all the model runs in a given iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b8279e81c4ace7bf",
   "metadata": {},
   "source": [
    "# Runs for a specific iteration (e.g., iteration 5).\n",
    "iteration_runs = [\n",
    "    run\n",
    "    for run in tracker.find_runs(parent_id=SCENARIO_RUN_ID, status=\"completed\")\n",
    "    if run.iteration == 5\n",
    "]\n",
    "iteration_run_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"model\": run.model_name,\n",
    "            \"run_id\": run.id,\n",
    "            \"iteration\": run.iteration,\n",
    "        }\n",
    "        for run in iteration_runs\n",
    "    ]\n",
    ")\n",
    "iteration_run_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "395d58c1bf230f7a",
   "metadata": {},
   "source": "We can find all the artifacts created during that iteration"
  },
  {
   "cell_type": "code",
   "id": "7a65dca03409d7db",
   "metadata": {},
   "source": [
    "iter5_artifacts = {\n",
    "    run.id: [artifact.key for artifact in tracker.find_artifacts(creator=run)]\n",
    "    for run in iteration_runs\n",
    "}\n",
    "iter5_artifacts"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "24d3f784230ea1d6",
   "metadata": {},
   "source": [
    "### Artifact Lineage\n",
    "\n",
    "The lineage tree shows how the final `skims` artifact traces back through the computational graph. Reading the tree:\n",
    "\n",
    "- Each **artifact** (like `skims`, `volumes`) shows its key and unique ID\n",
    "- Below each artifact is the **run** that produced it, with the step name, run ID, and iteration number\n",
    "- Indented below each run are its **input artifacts**, which recursively show their own producers\n",
    "\n",
    "This forms a DAG (directed acyclic graph) where you can trace any output back to the original inputs. With `max_depth=4`, we see four levels of this chain—in a 10-iteration model, the full lineage would be much deeper."
   ]
  },
  {
   "cell_type": "code",
   "id": "b7e77d2fe408a400",
   "metadata": {},
   "source": [
    "from rich import print as rprint\n",
    "from rich.tree import Tree\n",
    "\n",
    "\n",
    "def _add_lineage(branch, node):\n",
    "    artifact = node[\"artifact\"]\n",
    "    art_label = f\"{artifact.key} ({artifact.id})\"\n",
    "    art_branch = branch.add(art_label)\n",
    "    run_node = node.get(\"producing_run\")\n",
    "    if not run_node:\n",
    "        return\n",
    "    run = run_node[\"run\"]\n",
    "    run_label = f\"{run.model_name} run={run.id} iter={run.iteration}\"\n",
    "    run_branch = art_branch.add(run_label)\n",
    "    for child in run_node.get(\"inputs\", []):\n",
    "        _add_lineage(run_branch, child)\n",
    "\n",
    "\n",
    "final_skims = tracker.get_artifact(\"skims\")\n",
    "lineage = (\n",
    "    tracker.get_artifact_lineage(final_skims.id, max_depth=4) if final_skims else None\n",
    ")\n",
    "\n",
    "if lineage:\n",
    "    tree = Tree(\"lineage\")\n",
    "    _add_lineage(tree, lineage)\n",
    "    rprint(tree)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29dd7aaafa1a7476",
   "metadata": {},
   "source": [
    "# Which steps would re-run if parking costs changed?\n",
    "# Parking costs live in the zones artifact, so any run that consumes 'zones'\n",
    "# would be invalidated.\n",
    "zone_consumers = []\n",
    "for run in tracker.find_runs(parent_id=SCENARIO_RUN_ID, status=\"completed\"):\n",
    "    artifacts = tracker.get_artifacts_for_run(run.id)\n",
    "    if \"zones\" in artifacts.inputs:\n",
    "        zone_consumers.append(run)\n",
    "zone_consumer_df = pd.DataFrame(\n",
    "    [\n",
    "        {\"model\": run.model_name, \"run_id\": run.id, \"iteration\": run.iteration}\n",
    "        for run in zone_consumers\n",
    "    ]\n",
    ")\n",
    "zone_consumer_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e5cc68cc7fd362a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated three key provenance patterns:\n",
    "\n",
    "1. **Deep chains**: Each iteration's outputs become the next iteration's inputs, creating\n",
    "   traceable lineage dozens of steps deep.\n",
    "2. **Incremental computation**: Running 15 iterations after already running 10 reused all\n",
    "   prior work—only the new iterations executed.\n",
    "3. **Impact analysis**: We can query which steps consume a given artifact to understand\n",
    "   what would need to re-run if that artifact changed.\n",
    "\n",
    "The transportation model is a toy example, but the patterns apply to any iterative workflow:\n",
    "MCMC sampling, neural network training checkpoints, agent-based simulations, economic\n",
    "equilibrium models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
