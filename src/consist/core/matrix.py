"""
Consist Core Matrix Module

This module provides the `MatrixViewFactory`, which is responsible for creating
virtual xarray Datasets. These datasets consolidate multi-dimensional data
(matrices) that have been tracked by Consist, allowing for unified and lazy
loading of results across multiple runs.

Key functionalities include:
-   **Lazy Loading**: Data is loaded on-demand from Zarr stores, optimizing memory usage.
-   **Consolidation Across Runs**: Combines matrices from different runs into a
    single xarray Dataset, indexed by `run_id`, `year`, and `iteration`.
-   **Unified Access**: Provides a high-level interface to access complex
    multi-dimensional data structures generated by Consist workflows.
"""

from __future__ import annotations

import logging
from importlib import import_module
from types import ModuleType
from typing import TYPE_CHECKING, List, Optional

import pandas as pd
from sqlmodel import select

from consist.models.artifact import Artifact
from consist.models.run import Run

xr: Optional[ModuleType]
try:
    xr = import_module("xarray")
except ImportError:
    xr = None

if TYPE_CHECKING:
    from xarray import Dataset as XrDataset
    from consist.core.tracker import Tracker


class MatrixViewFactory:
    """
    A factory class responsible for creating virtual xarray Datasets from Consist's metadata.

    This factory allows users to query the Consist metadata catalog for multi-dimensional
    data (matrices) and lazily load the corresponding Zarr stores from disk. It consolidates
    data across different runs into a single, unified xarray Dataset, indexed by `run_id`,
    `year`, and `iteration`, facilitating comparative analysis and exploration.

    Attributes
    ----------
    tracker : Tracker
        An instance of the Consist `Tracker`, which provides access to the database
        engine and artifact resolution necessary for identifying and loading matrix data.
    """

    def __init__(self, tracker: Tracker) -> None:
        """
        Initializes the MatrixViewFactory with a reference to the Consist Tracker.

        Parameters
        ----------
        tracker : Tracker
            An instance of the Consist `Tracker`, providing access to the database
            for querying artifact and run metadata.
        """
        self.tracker = tracker

    def load_matrix_view(
        self,
        concept_key: str,
        variables: Optional[List[str]] = None,
        *,
        run_ids: Optional[List[str]] = None,
        parent_id: Optional[str] = None,
        model: Optional[str] = None,
        status: Optional[str] = None,
    ) -> "XrDataset":
        """
        Returns a lazy xarray Dataset containing all runs that match the `concept_key`.

        This method queries the Consist database for all matrix-type artifacts
        associated with the given `concept_key`. It then lazily opens each corresponding
        Zarr store using `xarray` and concatenates them into a single `xarray.Dataset`
        along a new `run_id` dimension. This allows for convenient analysis of
        multi-dimensional data across different experimental runs.

        Parameters
        ----------
        concept_key : str
            The semantic key (e.g., "model_output_grid", "simulation_results")
            identifying the collection of matrix artifacts to load.
        variables : Optional[List[str]], optional
            A list of variable names to load from each Zarr store. If `None`,
            all variables from each store will be loaded.
        run_ids : Optional[List[str]], optional
            Optional list of run IDs to include in the view.
        parent_id : Optional[str], optional
            Optional scenario/parent run ID to filter by.
        model : Optional[str], optional
            Optional model name to filter by.
        status : Optional[str], optional
            Optional run status to filter by (e.g., "completed").

        Returns
        -------
        xr.Dataset
            A lazy-loaded `xarray.Dataset` containing the combined data from all
            matching matrix artifacts, with a new `run_id` dimension and
            `year`/`iteration` coordinates. Returns an empty `xr.Dataset` if no
            matching artifacts are found or can be loaded.

        Raises
        ------
        ImportError
            If the `xarray` library is not installed.
        RuntimeError
            If the `Tracker` instance does not have a configured database connection.
        """
        if xr is None:
            raise ImportError("xarray is required.")
        if not self.tracker.engine:
            raise RuntimeError("Database connection required.")

        # 1. Query Metadata
        query = (
            select(
                Artifact.uri,
                Run.id.label("run_id"),
                Run.year,
                Run.iteration,
            )
            .join(Run, Artifact.run_id == Run.id)
            .where(Artifact.key == concept_key)
            .order_by(Run.year, Run.iteration)
        )
        if run_ids:
            query = query.where(Run.id.in_(run_ids))
        if parent_id:
            query = query.where(Run.parent_run_id == parent_id)
        if model:
            query = query.where(Run.model_name == model)
        if status:
            query = query.where(Run.status == status)
        df = pd.read_sql(query, self.tracker.engine)
        if df.empty:
            return xr.Dataset()

        # 2. Lazy Open & Stack
        datasets = []
        for _, row in df.iterrows():
            try:
                uri = row["uri"]
                path = self.tracker.resolve_uri(uri)

                ds = xr.open_zarr(path, consolidated=False)
                if variables:
                    ds = ds[variables]

                # FIX: Stack along 'run_id' dimension.
                # Treat 'year' and 'iteration' as metadata (coords) for that run.
                ds = ds.assign_coords(
                    {"year": row["year"] or 0, "iteration": row["iteration"] or 0}
                )
                # Expand run_id to be the primary concatenation dimension
                ds = ds.expand_dims(run_id=[row["run_id"]])

                datasets.append(ds)
            except Exception as e:
                logging.warning(f"[Consist Warning] Failed to load matrix {uri}: {e}")
                continue

        if not datasets:
            return xr.Dataset()

        # 3. Combine
        # Use concat to keep dimensions dense (avoiding sparse NaNs)
        return xr.concat(datasets, dim="run_id")
