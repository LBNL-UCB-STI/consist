{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Workflows and Provenance Chains\n",
    "\n",
    "Iterative equilibrium workflows show up all over scientific computing: transportation, economics,\n",
    "agent-based simulation, MCMC, and more. The pattern is simple: outputs from one step become inputs\n",
    "to the next until the system converges.\n",
    "\n",
    "This tutorial focuses on Consist mechanics, not transportation modeling. You can treat the model\n",
    "functions as black boxes and still learn the key patterns.\n",
    "\n",
    "**Prerequisites:** Quickstart and Concepts Overview.\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "- How Consist tracks deep, multi-step iteration chains\n",
    "- How incremental runs skip work you already computed\n",
    "- How to query lineage to understand impact and reproducibility\n",
    "\n",
    "## The model in 30 seconds\n",
    "\n",
    "People choose how to travel, car trips create congestion, and congestion feeds back into the next\n",
    "round of choices. We run 10 iterations and watch the system stabilize.\n"
   ],
   "id": "95d480df17200492"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We initialize the tracker and load the model functions. The details of the model live in\n",
    "`examples/src/travel_demand_functions.py`, but we treat them as implementation details here.\n"
   ],
   "id": "d5d7706807ad8ae7"
  },
  {
   "cell_type": "code",
   "id": "cb92e76e1e4227e1",
   "metadata": {},
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for candidate in (start, *start.parents):\n",
    "        if (candidate / \"pyproject.toml\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Could not locate repo root (missing pyproject.toml)\")\n",
    "\n",
    "\n",
    "REPO_ROOT = _find_repo_root(Path.cwd())\n",
    "EXAMPLES_DIR = REPO_ROOT / \"examples\"\n",
    "EXAMPLES_SRC = EXAMPLES_DIR / \"src\"\n",
    "\n",
    "for path in (REPO_ROOT, EXAMPLES_SRC):\n",
    "    if str(path) not in sys.path:\n",
    "        sys.path.insert(0, str(path))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f10d240ad42d3a85",
   "metadata": {},
   "source": [
    "from dataclasses import asdict, replace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import consist\n",
    "from consist import Tracker\n",
    "\n",
    "from travel_demand_functions import (\n",
    "    AssignmentParams,\n",
    "    DestinationChoiceParams,\n",
    "    ModeChoiceParams,\n",
    "    TravelDemandScenarioConfig,\n",
    "    ZoneParams,\n",
    "    apply_congestion,\n",
    "    apply_mode_choice,\n",
    "    compute_mode_shares,\n",
    "    compute_mode_utilities,\n",
    "    compute_od_logsums,\n",
    "    compute_od_volumes,\n",
    "    create_skims_dataset,\n",
    "    distribute_trips,\n",
    "    generate_distances,\n",
    "    generate_population,\n",
    "    generate_zones,\n",
    "    save_skims,\n",
    "    summarize_iteration,\n",
    ")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "440e59f91d965d55",
   "metadata": {},
   "source": [
    "EXAMPLES_DIR = REPO_ROOT / \"examples\"\n",
    "RUN_DIR = EXAMPLES_DIR / \"runs\" / \"travel_demand_demo\"\n",
    "SESSION_ID = os.getenv(\"CONSIST_SESSION_ID\", \"demo\")\n",
    "DB_PATH = RUN_DIR / f\"travel_demand_demo_{SESSION_ID}.duckdb\"\n",
    "if DB_PATH.exists():\n",
    "    DB_PATH.unlink()\n",
    "\n",
    "tracker = Tracker(\n",
    "    run_dir=RUN_DIR,\n",
    "    db_path=DB_PATH,\n",
    "    hashing_strategy=\"fast\",\n",
    "    project_root=str(RUN_DIR),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "\n",
    "We set up a small, fixed configuration for a 5-zone linear city. The parameters aren't important\n",
    "for understanding Consist—what matters is that the model is iterative and produces artifacts each step.\n"
   ],
   "id": "a0b022408721b6d7"
  },
  {
   "cell_type": "code",
   "id": "3047e99cf95e8869",
   "metadata": {},
   "source": [
    "zone_params = ZoneParams()\n",
    "mode_params = ModeChoiceParams()\n",
    "dest_params = DestinationChoiceParams()\n",
    "assignment_params = AssignmentParams()\n",
    "\n",
    "DEFAULT_SEED = 0\n",
    "\n",
    "base_config = TravelDemandScenarioConfig(\n",
    "    n_iterations=10,\n",
    "    seed=DEFAULT_SEED,\n",
    "    zone_params=zone_params,\n",
    "    mode_params=mode_params,\n",
    "    dest_params=dest_params,\n",
    "    assignment_params=assignment_params,\n",
    ")\n",
    "\n",
    "SCENARIO_NAME = \"travel_demand_demo\"\n",
    "\n",
    "SKIM_PERTURBATION = 0.1\n",
    "DESTINATION_UPDATE_SHARE = 0.2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Structure (Iteration Loop)\n",
    "\n",
    "The loop below is the conceptual anchor. Each iteration consumes the previous iteration's\n",
    "`skims` (travel times), produces new trips, assigns congestion, and updates `skims` again.\n",
    "\n",
    "```\n",
    "┌─────────────┐\n",
    "│    init     │ (iteration 0 only)\n",
    "└──────┬──────┘\n",
    "       │ skims, zones, population\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│   logsums   │◄─── skims, zones\n",
    "└──────┬──────┘\n",
    "       │ logsums\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ trip_dist   │◄─── logsums, zones, population\n",
    "└──────┬──────┘\n",
    "       │ trips\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ utilities   │◄─── trips, skims, zones\n",
    "└──────┬──────┘\n",
    "       │ utilities\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ mode_choice │◄─── utilities, (prev trips_with_modes)\n",
    "└──────┬──────┘\n",
    "       │ trips_with_modes\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ assignment  │◄─── trips_with_modes\n",
    "└──────┬──────┘\n",
    "       │ volumes\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ traffic_sim │◄─── volumes, skims\n",
    "└──────┬──────┘\n",
    "       │ updated skims ──► next iteration\n",
    "       ▼\n",
    "```\n",
    "\n",
    "For a quick explanation of `run(...)` vs `trace(...)`, see the\n",
    "[Concepts Overview](../docs/concepts.md#when-to-use-each-pattern).\n"
   ],
   "id": "4db126fb6d11e666"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified run loop (shape only)\n",
    "\n",
    "Below is a compact outline of the iterative loop. The full implementation (with logging and plotting) follows.\n",
    "\n",
    "```python\n",
    "def run_scenario(scenario_config, scenario_run_id):\n",
    "    with tracker.scenario(scenario_run_id, config=..., tags=[...]) as scenario:\n",
    "        scenario.run(name=\"init\", fn=initialize_scenario, ...)\n",
    "        for i in range(scenario_config.n_iterations):\n",
    "            with scenario.trace(name=\"logsums\", ...):\n",
    "                ...\n",
    "            scenario.run(name=\"trip_distribution\", ...)\n",
    "            scenario.run(name=\"calculate_utilities\", ...)\n",
    "            scenario.run(name=\"mode_choice\", ...)\n",
    "            scenario.run(name=\"assignment\", ...)\n",
    "            scenario.run(name=\"traffic_simulation\", ...)\n",
    "        scenario.run(name=\"summaries\", ...)\n",
    "    return results\n",
    "```\n"
   ],
   "id": "d03e617858312cb2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Functions (black box)\n",
    "\n",
    "The cell below contains the full workflow definition. It's long, but you don't need to read it\n",
    "line-by-line to follow the Consist concepts. The main takeaway is that each step logs artifacts\n",
    "that the next step can reuse.\n"
   ],
   "id": "e9c11ddbb681fa10"
  },
  {
   "cell_type": "code",
   "id": "4e89891d25158363",
   "metadata": {},
   "source": [
    "@tracker.define_step(outputs=[\"skims\", \"persons\", \"zones\"])\n",
    "def initialize_scenario(*, zone_params, mode_params, skim_perturbation, _consist_ctx):\n",
    "    zones = generate_zones(zone_params)\n",
    "    population = generate_population(zones)\n",
    "    distances = generate_distances(zone_params)\n",
    "\n",
    "    skims = create_skims_dataset(zones, distances, mode_params)\n",
    "    skims[\"time_car_mins\"] *= skim_perturbation\n",
    "\n",
    "    output_dir = _consist_ctx.run_dir\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    input_skims_path = output_dir / \"skims_init.zarr\"\n",
    "\n",
    "    save_skims(skims, input_skims_path)\n",
    "\n",
    "    consist.log_artifact(input_skims_path, key=\"skims\", direction=\"output\")\n",
    "    consist.log_dataframe(\n",
    "        population,\n",
    "        key=\"persons\",\n",
    "        direction=\"output\",\n",
    "    )\n",
    "    consist.log_dataframe(zones, key=\"zones\", direction=\"output\")\n",
    "\n",
    "\n",
    "@tracker.define_step(outputs=[\"trips\"])\n",
    "def distribute_trips_step(*, dest_params, seed, update_share, _consist_ctx):\n",
    "    zones = _consist_ctx.load(\"zones\")\n",
    "    population = _consist_ctx.load(\"persons\")\n",
    "    prev_trips_art = _consist_ctx.inputs.get(\"trips\")\n",
    "    prev_trips = _consist_ctx.load(prev_trips_art) if prev_trips_art else None\n",
    "    logsums_df = _consist_ctx.load(\"logsums\")\n",
    "    if \"origin\" not in logsums_df.columns or \"destination\" not in logsums_df.columns:\n",
    "        logsums_df = logsums_df.reset_index()\n",
    "    logsums = logsums_df.set_index([\"origin\", \"destination\"])[\"logsum\"].to_xarray()\n",
    "    trips = distribute_trips(\n",
    "        population,\n",
    "        zones,\n",
    "        logsums,\n",
    "        dest_params,\n",
    "        seed=seed,\n",
    "        prev_trips=prev_trips,\n",
    "        update_share=update_share,\n",
    "    )\n",
    "    consist.log_dataframe(trips, key=\"trips\")\n",
    "\n",
    "\n",
    "@tracker.define_step(\n",
    "    outputs=[\n",
    "        \"mode_shares\",\n",
    "        \"iteration_summaries\",\n",
    "        \"pmt_totals\",\n",
    "        \"mode_shares_plot\",\n",
    "        \"iteration_totals_plot\",\n",
    "    ]\n",
    ")\n",
    "def summarize_results_step(*, mode_shares, summaries, pmt_totals, _consist_ctx):\n",
    "    output_dir = _consist_ctx.run_dir\n",
    "    summary_dir = output_dir / \"summary\"\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    mode_shares_df = (\n",
    "        pd.DataFrame.from_dict(mode_shares, orient=\"index\")\n",
    "        .sort_index()\n",
    "        .rename_axis(\"iteration\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    summaries_df = (\n",
    "        pd.DataFrame.from_dict(summaries, orient=\"index\")\n",
    "        .sort_values(\"iteration\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    pmt_totals_df = (\n",
    "        pd.DataFrame.from_dict(pmt_totals, orient=\"index\")\n",
    "        .sort_index()\n",
    "        .rename_axis(\"iteration\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    mode_shares_path = summary_dir / \"mode_shares.csv\"\n",
    "    summaries_path = summary_dir / \"iteration_summaries.csv\"\n",
    "    pmt_totals_path = summary_dir / \"pmt_totals.csv\"\n",
    "\n",
    "    shares_long = mode_shares_df.melt(\n",
    "        id_vars=\"iteration\", var_name=\"mode\", value_name=\"share\"\n",
    "    )\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.lineplot(data=shares_long, x=\"iteration\", y=\"share\", hue=\"mode\", marker=\"o\")\n",
    "    plt.title(\"Mode Shares by Iteration\")\n",
    "    plt.tight_layout()\n",
    "    mode_share_plot_path = summary_dir / \"mode_shares.png\"\n",
    "    plt.savefig(mode_share_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    pmt_long = pmt_totals_df.melt(\n",
    "        id_vars=\"iteration\", var_name=\"mode\", value_name=\"pmt\"\n",
    "    )\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    sns.lineplot(data=summaries_df, x=\"iteration\", y=\"vmt\", marker=\"o\", ax=axes[0])\n",
    "    axes[0].set_title(\"Vehicle Miles Traveled\")\n",
    "    sns.lineplot(\n",
    "        data=pmt_long,\n",
    "        x=\"iteration\",\n",
    "        y=\"pmt\",\n",
    "        hue=\"mode\",\n",
    "        marker=\"o\",\n",
    "        ax=axes[1],\n",
    "    )\n",
    "    axes[1].set_title(\"Person Miles Traveled by Mode\")\n",
    "    fig.tight_layout()\n",
    "    totals_plot_path = summary_dir / \"iteration_totals.png\"\n",
    "    fig.savefig(totals_plot_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "    consist.log_dataframe(\n",
    "        mode_shares_df,\n",
    "        key=\"mode_shares\",\n",
    "        path=mode_shares_path,\n",
    "    )\n",
    "    consist.log_dataframe(\n",
    "        summaries_df,\n",
    "        key=\"iteration_summaries\",\n",
    "        path=summaries_path,\n",
    "    )\n",
    "    consist.log_dataframe(\n",
    "        pmt_totals_df,\n",
    "        key=\"pmt_totals\",\n",
    "        path=pmt_totals_path,\n",
    "    )\n",
    "    consist.log_artifact(\n",
    "        mode_share_plot_path,\n",
    "        key=\"mode_shares_plot\",\n",
    "        direction=\"output\",\n",
    "    )\n",
    "    consist.log_artifact(\n",
    "        totals_plot_path,\n",
    "        key=\"iteration_totals_plot\",\n",
    "        direction=\"output\",\n",
    "    )\n",
    "\n",
    "\n",
    "def run_scenario(scenario_config, scenario_run_id):\n",
    "    mode_shares = {}\n",
    "    summaries = {}\n",
    "    pmt_totals = {}\n",
    "\n",
    "    zone_params = scenario_config.zone_params\n",
    "    mode_params = scenario_config.mode_params\n",
    "    dest_params = scenario_config.dest_params\n",
    "    assignment_params = scenario_config.assignment_params\n",
    "    seed = scenario_config.seed\n",
    "\n",
    "    with tracker.scenario(\n",
    "        scenario_run_id,\n",
    "        config={\n",
    "            **asdict(scenario_config),\n",
    "            \"scenario_name\": SCENARIO_NAME,\n",
    "        },\n",
    "        facet_from=[\"n_iterations\"],\n",
    "        tags=[\"examples\", \"simulation\", \"travel_demand\"],\n",
    "    ) as scenario:\n",
    "        cache_validation = \"lazy\"  # Skip output checks on cache hits for speed; use 'eager' to validate files.\n",
    "        cache_hydration = (\n",
    "            \"inputs-missing\"  # Copy cached inputs into the new run_dir on cache misses.\n",
    "        )\n",
    "\n",
    "        scenario.run(\n",
    "            name=\"init\",\n",
    "            fn=initialize_scenario,\n",
    "            config=asdict(mode_params)\n",
    "            | asdict(zone_params)\n",
    "            | {\"skim_perturbation\": SKIM_PERTURBATION},\n",
    "            facet_from=[\"skim_perturbation\"],\n",
    "            inject_context=True,\n",
    "            fn_args={\n",
    "                \"zone_params\": zone_params,\n",
    "                \"mode_params\": mode_params,\n",
    "                \"skim_perturbation\": SKIM_PERTURBATION,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        for i in tqdm(range(scenario_config.n_iterations)):\n",
    "            # Inline trace pattern (no wrapper function required).\n",
    "            with scenario.trace(\n",
    "                name=\"logsums\",\n",
    "                run_id=f\"{scenario.run_id}_logsums_{i}\",\n",
    "                config=asdict(mode_params),\n",
    "                inputs={\"skims\": \"skims\", \"zones\": \"zones\"},\n",
    "                facet_from=[\n",
    "                    \"beta_cost\",\n",
    "                    \"beta_time\",\n",
    "                    \"asc_walk\",\n",
    "                    \"asc_transit\",\n",
    "                    \"fuel_cost_per_mile\",\n",
    "                    \"transit_fare\",\n",
    "                ],\n",
    "                validate_cached_outputs=cache_validation,\n",
    "                cache_hydration=cache_hydration,\n",
    "                iteration=i,\n",
    "            ) as t:\n",
    "                if not t.is_cached:\n",
    "                    logsums = compute_od_logsums(\n",
    "                        t.load(scenario.coupler.require(\"skims\")),\n",
    "                        t.load(scenario.coupler.require(\"zones\")),\n",
    "                        mode_params,\n",
    "                    )\n",
    "                    consist.log_dataframe(\n",
    "                        logsums.to_dataframe().reset_index(),\n",
    "                        key=\"logsums\",\n",
    "                    )\n",
    "\n",
    "            scenario.run(\n",
    "                name=\"trip_distribution\",\n",
    "                fn=distribute_trips_step,\n",
    "                run_id=f\"{scenario.run_id}_trip_distribution_{i}\",\n",
    "                config={\n",
    "                    **asdict(dest_params),\n",
    "                    \"update_share\": DESTINATION_UPDATE_SHARE,\n",
    "                },\n",
    "                inputs={\n",
    "                    \"skims\": \"skims\",\n",
    "                    \"zones\": \"zones\",\n",
    "                    \"persons\": \"persons\",\n",
    "                    \"logsums\": \"logsums\",\n",
    "                },\n",
    "                optional_input_keys=[\"trips\"],\n",
    "                facet_from=[\"beta_size\", \"beta_access\", \"update_share\"],\n",
    "                inject_context=True,\n",
    "                fn_args={\n",
    "                    \"dest_params\": dest_params,\n",
    "                    \"seed\": seed + i,\n",
    "                    \"update_share\": DESTINATION_UPDATE_SHARE,\n",
    "                },\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            # `load_inputs=True` hydrates artifacts into function args by name.\n",
    "            scenario.run(\n",
    "                name=\"calculate_utilities\",\n",
    "                fn=compute_mode_utilities,\n",
    "                run_id=f\"{scenario.run_id}_utilities_{i}\",\n",
    "                config=asdict(mode_params),\n",
    "                inputs={\"trips\": \"trips\", \"skims\": \"skims\", \"zones\": \"zones\"},\n",
    "                facet_from=[\n",
    "                    \"beta_cost\",\n",
    "                    \"beta_time\",\n",
    "                    \"asc_walk\",\n",
    "                    \"asc_transit\",\n",
    "                ],\n",
    "                validate_cached_outputs=cache_validation,\n",
    "                cache_hydration=cache_hydration,\n",
    "                load_inputs=True,\n",
    "                fn_args={\"mode_params\": mode_params},\n",
    "                outputs=[\"utilities\"],\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            mode_choice_result = scenario.run(\n",
    "                name=\"mode_choice\",\n",
    "                fn=apply_mode_choice,\n",
    "                run_id=f\"{scenario.run_id}_mode_choice_{i}\",\n",
    "                config={\"seed\": seed},\n",
    "                inputs={\"utilities_df\": \"utilities\"},\n",
    "                fn_args={\"seed\": seed + i},\n",
    "                outputs=[\"trips_with_modes\"],\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            scenario.run(\n",
    "                name=\"assignment\",\n",
    "                fn=compute_od_volumes,\n",
    "                run_id=f\"{scenario.run_id}_assignment_{i}\",\n",
    "                inputs={\"trips\": \"trips_with_modes\"},\n",
    "                outputs=[\"volumes\"],\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            scenario.run(\n",
    "                name=\"traffic_simulation\",\n",
    "                fn=apply_congestion,\n",
    "                run_id=f\"{scenario.run_id}_traffic_simulation_{i}\",\n",
    "                config=asdict(assignment_params),\n",
    "                inputs={\"volumes\": \"volumes\", \"skims\": \"skims\"},\n",
    "                facet_from=[\"bpr_alpha\", \"bpr_beta\", \"base_capacity\"],\n",
    "                fn_args={\"assignment_params\": assignment_params},\n",
    "                outputs=[\"skims\"],\n",
    "                iteration=i,\n",
    "            )\n",
    "\n",
    "            trips_with_modes = tracker.load(\n",
    "                mode_choice_result.outputs[\"trips_with_modes\"]\n",
    "            )\n",
    "            shares = compute_mode_shares(trips_with_modes)\n",
    "            mode_shares[i] = pd.Series(shares)\n",
    "            distance_by_mode = trips_with_modes.groupby(\"mode\")[\"distance_miles\"].sum()\n",
    "            pmt_totals[i] = distance_by_mode.sort_index()\n",
    "            summaries[i] = summarize_iteration(i, trips_with_modes, shares, 0, False)\n",
    "\n",
    "        summary_result = scenario.run(\n",
    "            name=\"summaries\",\n",
    "            fn=summarize_results_step,\n",
    "            inputs={\"trips_with_modes\": \"trips_with_modes\"},\n",
    "            inject_context=True,\n",
    "            validate_cached_outputs=cache_validation,\n",
    "            cache_hydration=cache_hydration,\n",
    "            fn_args={\n",
    "                \"mode_shares\": mode_shares,\n",
    "                \"summaries\": summaries,\n",
    "                \"pmt_totals\": pmt_totals,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        mode_shares_df = tracker.load(summary_result.outputs[\"mode_shares\"])\n",
    "        summaries_df = tracker.load(summary_result.outputs[\"iteration_summaries\"])\n",
    "        pmt_totals_df = tracker.load(summary_result.outputs[\"pmt_totals\"])\n",
    "        mode_share_plot_path = Path(\n",
    "            tracker.resolve_uri(summary_result.outputs[\"mode_shares_plot\"].uri)\n",
    "        )\n",
    "        totals_plot_path = Path(\n",
    "            tracker.resolve_uri(summary_result.outputs[\"iteration_totals_plot\"].uri)\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"scenario_run_id\": scenario_run_id,\n",
    "        \"mode_shares_df\": mode_shares_df,\n",
    "        \"summaries_df\": summaries_df,\n",
    "        \"pmt_totals_df\": pmt_totals_df,\n",
    "        \"mode_share_plot_path\": mode_share_plot_path,\n",
    "        \"totals_plot_path\": totals_plot_path,\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Run (10 iterations)\n",
    "\n",
    "We run the baseline scenario and capture a single plot to confirm the model converges.\n"
   ],
   "id": "32226e5c227dc637"
  },
  {
   "cell_type": "code",
   "id": "a50e498953b5b49c",
   "metadata": {},
   "source": [
    "base_run_id = f\"{SCENARIO_NAME}_{SESSION_ID}\"\n",
    "base_results = run_scenario(base_config, base_run_id)\n",
    "\n",
    "analysis = base_results\n",
    "\n",
    "mode_shares_df = analysis[\"mode_shares_df\"]\n",
    "summaries_df = analysis[\"summaries_df\"]\n",
    "pmt_totals_df = analysis[\"pmt_totals_df\"]\n",
    "mode_share_plot_path = analysis[\"mode_share_plot_path\"]\n",
    "totals_plot_path = analysis[\"totals_plot_path\"]\n",
    "SCENARIO_RUN_ID = analysis[\"scenario_run_id\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence check\n",
    "\n",
    "The plot below shows mode shares stabilizing over iterations.\n"
   ],
   "id": "3027b3e247dde1dd"
  },
  {
   "cell_type": "code",
   "id": "a1e813675e09be2a",
   "metadata": {},
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=str(mode_share_plot_path))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifact Lineage\n",
    "\n",
    "The lineage tree shows how the final `skims` artifact traces back through the computational graph.\n",
    "Reading the tree:\n",
    "\n",
    "- Each **artifact** (like `skims`, `volumes`) shows its key and unique ID\n",
    "- Below each artifact is the **run** that produced it, with the step name, run ID, and iteration number\n",
    "- Indented below each run are its **input artifacts**, which recursively show their own producers\n",
    "\n",
    "This forms a DAG (directed acyclic graph) where you can trace any output back to the original inputs.\n",
    "With `max_depth=4`, we see four levels of this chain—in a 10-iteration model, the full lineage would\n",
    "be much deeper.\n"
   ],
   "id": "d986f2d2a45c3c63"
  },
  {
   "cell_type": "code",
   "id": "b7e77d2fe408a400",
   "metadata": {},
   "source": [
    "from rich import print as rprint\n",
    "from rich.tree import Tree\n",
    "\n",
    "\n",
    "def _add_lineage(branch, node):\n",
    "    artifact = node[\"artifact\"]\n",
    "    art_label = f\"{artifact.key} ({artifact.id})\"\n",
    "    art_branch = branch.add(art_label)\n",
    "    run_node = node.get(\"producing_run\")\n",
    "    if not run_node:\n",
    "        return\n",
    "    run = run_node[\"run\"]\n",
    "    run_label = f\"{run.model_name} run={run.id} iter={run.iteration}\"\n",
    "    run_branch = art_branch.add(run_label)\n",
    "    for child in run_node.get(\"inputs\", []):\n",
    "        _add_lineage(run_branch, child)\n",
    "\n",
    "\n",
    "final_skims = tracker.get_artifact(\"skims\")\n",
    "lineage = (\n",
    "    tracker.get_artifact_lineage(final_skims.id, max_depth=4) if final_skims else None\n",
    ")\n",
    "\n",
    "if lineage:\n",
    "    tree = Tree(\"lineage\")\n",
    "    _add_lineage(tree, lineage)\n",
    "    rprint(tree)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental Computation Demo\n",
    "\n",
    "We ran the baseline scenario for 10 iterations above. Now we extend to 15 iterations. Since the\n",
    "extended run shares the same parameters for iterations 0-9, Consist should recognize those steps\n",
    "have already been computed and skip them—only running iterations 10 through 14.\n"
   ],
   "id": "5c0186925646c8b0"
  },
  {
   "cell_type": "code",
   "id": "62b98f798bf484c5",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CONSIST_CACHE_DEBUG\"] = (\n",
    "    \"1\"  # Log cache hits/misses during the incremental run.\n",
    ")\n",
    "extended_config = replace(base_config, n_iterations=15)\n",
    "extended_run_id = f\"{SCENARIO_NAME}_{SESSION_ID}_extended\"\n",
    "extended_results = run_scenario(extended_config, extended_run_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b66742136899be3",
   "metadata": {},
   "source": [
    "# Quick cache-hit check for the extended run.\n",
    "cached_runs = [\n",
    "    run\n",
    "    for run in tracker.find_runs(parent_id=extended_results[\"scenario_run_id\"])\n",
    "    if run.meta.get(\"cache_hit\")\n",
    "]\n",
    "[(run.model_name, run.iteration, run.id) for run in cached_runs]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, all steps from iterations 0-9 were retrieved from cache. The extended run only\n",
    "computed the 5 new iterations, demonstrating how Consist enables incremental refinement of\n",
    "iterative models.\n"
   ],
   "id": "a2cea6eea1d6a2d4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cached runs and on-disk outputs\n",
    "\n",
    "Because iterations 0-9 were cache hits, Consist does not re-run those steps or write their output\n",
    "files under `examples/runs/travel_demand_demo/outputs/travel_demand_demo_demo_extended/`. The run\n",
    "records and artifacts still exist in the database, and the original files still live in the earlier\n",
    "run's output directory. If you want copies in a new location, you can materialize those cached\n",
    "artifacts on demand.\n",
    "\n",
    "See: [Caching and Hydration](../docs/caching-and-hydration.md) for more detail.\n"
   ],
   "id": "c014e26c71e0ec03"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from consist.core.materialize import materialize_artifacts\n",
    "\n",
    "extended_outputs_dir = RUN_DIR / \"outputs\" / extended_run_id\n",
    "extended_parquet = sorted(\n",
    "    p.relative_to(extended_outputs_dir)\n",
    "    for p in extended_outputs_dir.rglob(\"*.parquet\")\n",
    ")\n",
    "extended_parquet[:10]\n",
    "\n",
    "cached_run = next(\n",
    "    run\n",
    "    for run in tracker.find_runs(parent_id=extended_results[\"scenario_run_id\"], model=\"mode_choice\")\n",
    "    if run.iteration == 3 and run.meta.get(\"cache_hit\")\n",
    ")\n",
    "cached_outputs = tracker.find_artifacts(creator=cached_run, direction=\"output\")\n",
    "cached_parquet = [\n",
    "    art\n",
    "    for art in cached_outputs\n",
    "    if Path(tracker.resolve_uri(art.uri)).suffix == \".parquet\"\n",
    "]\n",
    "cached_parquet_paths = [Path(tracker.resolve_uri(art.uri)) for art in cached_parquet]\n",
    "[str(path).startswith(str(extended_outputs_dir)) for path in cached_parquet_paths[:3]]\n",
    "\n",
    "materialize_dir = RUN_DIR / \"outputs\" / f\"{extended_run_id}_materialized\"\n",
    "items = [\n",
    "    (art, materialize_dir / Path(tracker.resolve_uri(art.uri)).name)\n",
    "    for art in cached_parquet[:1]\n",
    "]\n",
    "materialize_artifacts(tracker, items)\n"
   ],
   "id": "8ea25b1b568d8cdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Provenance\n",
    "\n",
    "Now let's use Consist's query capabilities to explore runs and artifacts for a specific iteration.\n"
   ],
   "id": "9386a693c059d80d"
  },
  {
   "cell_type": "code",
   "id": "b8279e81c4ace7bf",
   "metadata": {},
   "source": [
    "# Runs for a specific iteration (e.g., iteration 5).\n",
    "iteration_runs = [\n",
    "    run\n",
    "    for run in tracker.find_runs(parent_id=SCENARIO_RUN_ID, status=\"completed\")\n",
    "    if run.iteration == 5\n",
    "]\n",
    "iteration_run_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"model\": run.model_name,\n",
    "            \"run_id\": run.id,\n",
    "            \"iteration\": run.iteration,\n",
    "        }\n",
    "        for run in iteration_runs\n",
    "    ]\n",
    ")\n",
    "iteration_run_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find all the artifacts created during that iteration.\n"
   ],
   "id": "55dd643d5d321ed0"
  },
  {
   "cell_type": "code",
   "id": "7a65dca03409d7db",
   "metadata": {},
   "source": [
    "iter5_artifacts = {\n",
    "    run.id: [artifact.key for artifact in tracker.find_artifacts(creator=run)]\n",
    "    for run in iteration_runs\n",
    "}\n",
    "iter5_artifacts"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29dd7aaafa1a7476",
   "metadata": {},
   "source": [
    "# Which steps would re-run if parking costs changed?\n",
    "# Parking costs live in the zones artifact, so any run that consumes 'zones'\n",
    "# would be invalidated.\n",
    "zone_consumers = []\n",
    "for run in tracker.find_runs(parent_id=SCENARIO_RUN_ID, status=\"completed\"):\n",
    "    artifacts = tracker.get_artifacts_for_run(run.id)\n",
    "    if \"zones\" in artifacts.inputs:\n",
    "        zone_consumers.append(run)\n",
    "zone_consumer_df = pd.DataFrame(\n",
    "    [\n",
    "        {\"model\": run.model_name, \"run_id\": run.id, \"iteration\": run.iteration}\n",
    "        for run in zone_consumers\n",
    "    ]\n",
    ")\n",
    "zone_consumer_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated three key provenance patterns:\n",
    "\n",
    "1. **Deep chains**: Each iteration's outputs become the next iteration's inputs, creating\n",
    "   traceable lineage dozens of steps deep.\n",
    "2. **Incremental computation**: Running 15 iterations after already running 10 reused all\n",
    "   prior work—only the new iterations executed.\n",
    "3. **Impact analysis**: We can query which steps consume a given artifact to understand\n",
    "   what would need to re-run if that artifact changed.\n",
    "\n",
    "These patterns apply to any iterative workflow: MCMC sampling, neural network training checkpoints,\n",
    "agent-based simulations, and economic equilibrium models.\n"
   ],
   "id": "5ed58a270d68dafd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
