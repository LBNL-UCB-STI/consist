from pathlib import Path
import pytest
import pandas as pd
import logging


@pytest.fixture
def dummy_input(tmp_path):
    """Creates a dummy input file and returns its path."""
    f = tmp_path / "source_data.csv"
    f.write_text("id,val\n1,100")
    return f


def test_caching_and_forking(tracker, dummy_input):
    """
    Tests Consist's core caching (cache hit) and run forking (lineage linking) mechanisms.

    This test verifies that Consist correctly identifies identical runs as cache hits
    and, when a run consumes an output from a previous run, automatically establishes
    a lineage link to that parent run. This is fundamental for reproducibility and efficiency.

    What happens:
    1. A `Tracker` and a dummy `input_file` are set up using the `tracker_setup` fixture.
    2. **Run A (Base Run)**: A `tracker.start_run` context ("run_A") is initiated with
       a specific configuration and the `input_file`. An output artifact is created
       and logged.
    3. **Run B (Identical Twin)**: A second `tracker.start_run` context ("run_B") is
       initiated with *identical* configuration and inputs as Run A.
    4. **Run C (Child/Lineage Test)**: A third `tracker.start_run` context ("run_C")
       is initiated. Its input is the *output artifact* generated by Run A.

    What's checked:
    -   **Run A**: The `config_hash` and `input_hash` are correctly calculated.
    -   **Run B**:
        - `t.current_consist.cached_run` is not `None`, indicating a cache hit.
        - The `cached_run.id` is "run_A", confirming it correctly identified the parent.
        - The `cached_run.status` is "completed".
    -   **Run C**:
        - `current_run.parent_run_id` is "run_A", verifying automatic lineage linking.
        - The input `Artifact` object within Run C correctly has its `run_id` set to "run_A",
          confirming that the provenance of the input was correctly tracked from its source.
    """
    config = {"param": 42}
    input_path = str(dummy_input)

    # 1. Run A: The Base Run
    logging.info("\n--- Starting Run A ---")
    with tracker.start_run(
            "run_A", model="test_model", config=config, inputs=[input_path]
    ) as t:
        # Create an output
        df = pd.DataFrame({"a": [1, 2]})
        out_path = t.run_dir / "run_A_out.parquet"
        df.to_parquet(out_path)
        t.log_artifact(out_path, key="intermediate", direction="output")

    # 2. Run B: The Identical Twin (Cache Test)
    logging.info("\n--- Starting Run B (Expect Cache Hit) ---")
    with tracker.start_run(
            "run_B", model="test_model", config=config, inputs=[input_path]
    ) as t:
        cached = t.current_consist.cached_run
        assert cached is not None, "Run B should have found Run A in cache"
        assert cached.id == "run_A"
        assert cached.status == "completed"

    # 3. Run C: The Child (Lineage/Forking Test)
    logging.info("\n--- Starting Run C (Expect Lineage Link) ---")
    prev_output = str(tracker.run_dir / "run_A_out.parquet")

    with tracker.start_run(
            "run_C", model="downstream_model", inputs=[prev_output]
    ) as t:
        current_run = t.current_consist.run
        assert current_run.parent_run_id == "run_A"

        # Verify input artifact lineage
        inp_artifact = t.current_consist.inputs[0]
        assert inp_artifact.run_id == "run_A"


def test_cache_overwrite_mode(tracker, dummy_input):
    """
    Tests the `cache_mode="overwrite"` functionality of `tracker.start_run`.

    This test verifies that when `cache_mode` is set to "overwrite", Consist
    will always execute the run (ignoring any existing cache entries for the
    same signature) and will update the cache with the results of the current run.
    It ensures that new results can forcibly replace older cached ones.

    What happens:
    1. A `Tracker` and a dummy `input_file` are set up.
    2. **Run A**: An initial run ("run_A_overwrite") is executed and completes,
       populating the cache with its results.
    3. **Run B**: An identical run ("run_B_overwrite") is executed, but with
       `cache_mode="overwrite"`.
    4. **Run C**: A third identical run ("run_C_overwrite") is executed with
       the default `cache_mode="reuse"`.

    What's checked:
    - After Run B (overwrite mode), `t.is_cached` is `False`, confirming that
      the cache was not used, and the run was executed.
    - After Run C (reuse mode), `t.is_cached` is `True`, confirming a cache hit.
    - Importantly, the `cached_run.id` for Run C is "run_B_overwrite", proving that
      Run B successfully updated the cache and replaced the entry from Run A.
    """
    config = {"param": 100}
    input_path = str(dummy_input)

    # 1. Run A: Populate cache
    with tracker.start_run(
            "run_A_overwrite", "overwrite_model", config=config, inputs=[input_path]
    ):
        pass

        # 2. Run B: Overwrite the cache
    logging.info("--- Starting Run B (Overwrite Mode) ---")
    with tracker.start_run(
            "run_B_overwrite",
            "overwrite_model",
            config=config,
            inputs=[input_path],
            cache_mode="overwrite",
    ) as t:
        assert not t.is_cached, "Run B in overwrite mode should not be cached."

    # 3. Run C: Check which run is now cached
    logging.info("--- Starting Run C (Expect Cache Hit on Run B) ---")
    with tracker.start_run(
            "run_C_overwrite",
            "overwrite_model",
            config=config,
            inputs=[input_path],
            cache_mode="reuse",
    ) as t:
        assert t.is_cached, "Run C should have a cache hit."
        cached_run = t.current_consist.cached_run
        assert cached_run.id == "run_B_overwrite"