{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad025a8",
   "metadata": {},
   "source": "# Parameter Sweeps with Provenance Tracking (Predator\u2013Prey)\n\n> **Prerequisites**\n>\n> This notebook assumes you've read the [Concepts Overview](../docs/concepts.md).\n\n\n## Notebook Goals\n\nBy the end of this notebook, you'll understand how to:\n- Track provenance automatically for parameter sweeps without manual bookkeeping\n- Use Consist's `scenario` and `step` abstractions to organize multi-run workflows\n- Separate cache identity (`config`) from queryable metadata (`facet`)\n- Query results across hundreds of runs using typed SQL views\u2014no raw SQL strings\n- Inspect the provenance database to understand what Consist stores\n\n\n## Why Provenance Tracking for Parameter Sweeps?\n\nWhen running Monte Carlo simulations or parameter sweeps, researchers often face questions like:\n- \"Which parameter settings produced that interesting result I saw last week?\"\n- \"Did I already run this configuration, or do I need to re-run it?\"\n- \"How do I compare results across different parameter regimes without manual bookkeeping?\"\n\nThis notebook shows how Consist answers these questions automatically by treating provenance as a first-class concern. Every simulation run is recorded with its full configuration, and results can be queried across the entire sweep using typed SQL views\u2014without writing any raw SQL or manually tracking file paths.\n\n## Outline\n\nThis notebook is a walkthrough of Consist in a scientific simulation workflow:\n\n1. Run a single simulation to preview the time series\n2. Define a sweep (parameters + seeds)\n3. Run one simulation per Consist step (each sweep member has provenance)\n4. Export a SQLModel stub for the series artifact\n5. Aggregate per-sim outputs with typed queries (no raw SQL)\n6. Visualize summary metrics\n7. Inspect what landed in the DuckDB file\n"
  },
  {
   "cell_type": "markdown",
   "id": "2ff392fd",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "This notebook writes outputs and DuckDB databases under `examples/runs/`.\n",
    "\n",
    "We initialize a `Tracker` instance, which is the central object in Consist. It manages:\n",
    "- **Run directory**: Where artifact files are stored on disk, organized by run\n",
    "- **Database**: A DuckDB file that indexes runs, artifacts, and enables cross-run queries\n",
    "- **Mounts**: Path mappings that make provenance portable across machines\n",
    "\n",
    "Each notebook session gets a unique database file (via `SESSION_ID`) so you can re-run the notebook multiple times without conflicts or stale cache hits from previous sessions. In production workflows, you'd typically use a persistent database path.\n",
    "\n",
    "> **Note**: The imports from `examples/src/pipeline_steps.py` and `examples/src/synth_simulation.py` contain the actual simulation logic. We've factored these out to keep the notebook focused on Consist's provenance features rather than model implementation details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f9a4b4024592c3e3",
   "metadata": {},
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import consist\n",
    "\n",
    "\n",
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for candidate in (start, *start.parents):\n",
    "        if (candidate / \"pyproject.toml\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Could not locate repo root (missing pyproject.toml)\")\n",
    "\n",
    "\n",
    "REPO_ROOT = _find_repo_root(Path.cwd())\n",
    "EXAMPLES_DIR = REPO_ROOT / \"examples\"\n",
    "EXAMPLES_SRC = EXAMPLES_DIR / \"src\"\n",
    "\n",
    "for path in (REPO_ROOT, EXAMPLES_SRC):\n",
    "    if str(path) not in sys.path:\n",
    "        sys.path.insert(0, str(path))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "520e36e7",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "from consist import Tracker, pivot_facets, run_query\n",
    "\n",
    "from pipeline_steps import (\n",
    "    build_sweep_registry,\n",
    "    make_run_id,\n",
    "    run_one_simulation,\n",
    "    write_parquet,\n",
    ")\n",
    "from synth_simulation import PredatorPreyConfig\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "RUN_DIR = EXAMPLES_DIR / \"runs\" / \"predator_prey_demo\"\n",
    "SESSION_ID = os.getenv(\"CONSIST_SESSION_ID\", \"demo\")\n",
    "DB_PATH = RUN_DIR / f\"predator_prey_demo_{SESSION_ID}.duckdb\"\n",
    "if DB_PATH.exists():\n",
    "    DB_PATH.unlink()\n",
    "artifact_root = RUN_DIR / \"analysis\"\n",
    "\n",
    "tracker = Tracker(run_dir=RUN_DIR, db_path=DB_PATH)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "## Workflow Functions and Instrumentation Choices\n",
    "\n",
    "This sweep uses two core functions and shows both `run(...)` and `trace(...)`. For the distinction, see the [Concepts Overview](../docs/concepts.md#when-to-use-each-pattern).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3246bb2",
   "metadata": {},
   "source": [
    "## 1) Single Simulation Preview\n",
    "\n",
    "Before running a full parameter sweep, it's useful to verify the model behaves as expected with a single configuration. This also helps us choose appropriate parameter ranges for the sweep.\n",
    "\n",
    "The Lotka-Volterra predator-prey model exhibits characteristic oscillatory dynamics: prey populations grow, predators feast and multiply, prey decline, predators starve\u2014and the cycle repeats. With stochastic dynamics (as implemented here), populations can also go extinct, which is one of the phenomena we'll explore in the sweep."
   ]
  },
  {
   "cell_type": "code",
   "id": "d42fcebd",
   "metadata": {},
   "source": [
    "base_config = PredatorPreyConfig(\n",
    "    steps=250,\n",
    "    sample_every=1,\n",
    "    prey_init=80,\n",
    "    predator_init=25,\n",
    "    predator_birth_efficiency=0.20,\n",
    ")\n",
    "\n",
    "preview_row = {\n",
    "    \"seed\": 7,\n",
    "    \"prey_birth_rate\": 0.70,\n",
    "    \"predation_rate\": 0.011,\n",
    "    \"predator_birth_efficiency\": 0.20,\n",
    "    \"predator_death_rate\": 0.18,\n",
    "}\n",
    "\n",
    "preview_series = run_one_simulation(\n",
    "    base_config=base_config,\n",
    "    registry_row=preview_row,\n",
    ")\n",
    "display(preview_series.head())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(preview_series[\"t\"], preview_series[\"prey\"], label=\"prey\")\n",
    "ax.plot(preview_series[\"t\"], preview_series[\"predator\"], label=\"predator\")\n",
    "ax.set_title(\"Single-run trajectory (preview)\")\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"population\")\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "64f32d0f",
   "metadata": {},
   "source": [
    "## 2) Define the Sweep\n",
    "\n",
    "We construct a **registry**\u2014a DataFrame where each row represents one simulation to run. The registry includes:\n",
    "- **Parameter combinations**: Different values of prey birth rate, predation rate, etc.\n",
    "- **Replicates**: Multiple runs per parameter setting (with different random seeds) to capture stochastic variation\n",
    "- **Identifiers**: Unique IDs that we'll use as Consist run IDs\n",
    "\n",
    "### Why a Registry?\n",
    "\n",
    "This pattern separates \"what to run\" from \"how to run it,\" which provides several benefits:\n",
    "- **Resumability**: If the sweep crashes partway through, you can filter to incomplete rows and continue\n",
    "- **Reproducibility**: The registry itself can be versioned and shared\n",
    "- **Flexibility**: Easy to add/remove parameter combinations or increase replicates\n",
    "\n",
    "The registry contains two ID columns:\n",
    "- `sim_id`: Unique identifier for each simulation (one per row)\n",
    "- `setting_id`: Shared across replicates of the same parameter combination\u2014useful for grouping in analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5723fb4",
   "metadata": {},
   "source": [
    "registry = build_sweep_registry(\n",
    "    # Tuned grid to highlight a transition region (coexistence \u2194 extinction).\n",
    "    # (The stochastic dynamics can be sensitive; this set usually shows mixed regimes.)\n",
    "    prey_birth_rates=[0.60, 0.7, 0.75],\n",
    "    predation_rates=[0.008, 0.011, 0.014],\n",
    "    predator_death_rates=[0.15],\n",
    "    predator_birth_efficiency=0.20,\n",
    "    replicates_per_setting=10,\n",
    "    seed=7,\n",
    ")\n",
    "print(f\"sims={len(registry)} settings={registry['setting_id'].nunique()}\")\n",
    "registry.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d1272f97",
   "metadata": {},
   "source": [
    "## 3) Running the Sweep with Provenance Tracking\n",
    "\n",
    "This is where Consist shines. Each simulation becomes a **step** within a parent **scenario**, and Consist automatically:\n",
    "\n",
    "1. **Records configuration**: The full parameter set is stored as both a cache key and queryable metadata\n",
    "2. **Tracks artifacts**: Output files are logged with content hashes, enabling cache validation and lineage queries\n",
    "3. **Enables caching**: If you re-run this cell, Consist will detect matching signatures and skip redundant computation\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Scenarios and Steps**\n",
    "\n",
    "A `scenario` groups related runs under a common parent. Think of it as a \"study\" or \"experiment.\" Each `step` within a scenario is an individual run with its own:\n",
    "- Configuration (which drives caching)\n",
    "- Artifacts (inputs and outputs)\n",
    "- Metadata (tags, facets, timestamps)\n",
    "\n",
    "This hierarchy lets you ask questions like \"show me all runs from the baseline scenario\" or \"compare results across scenarios.\"\n",
    "\n",
    "**`config=` vs `facet=`: Cache Identity vs Queryability**\n",
    "\n",
    "This distinction is crucial:\n",
    "\n",
    "| Parameter | Purpose                                                                                                                                                       | Effect                                                         |\n",
    "|-----------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------|\n",
    "| `config=` | **Cache identity**. A hash of this dictionary (combined with code version and input hashes) determines whether Consist reuses a cached result or re-executes. | Changing any value invalidates the cache for this run.         |\n",
    "| `facet=`  | **Queryable metadata**. Stored in DuckDB with indexed keys for efficient filtering. Does *not* affect cache identity.                                         | You can filter runs by facet values without loading artifacts. |\n",
    "\n",
    "Why separate them? Sometimes you want to store metadata that shouldn't affect caching (e.g., human-readable labels, denormalized fields for query convenience). The facet gives you a queryable \"index\" over your runs.\n",
    "\n",
    "When facets are a subset of the config, use `facet_from=[...]` to extract keys directly from `config` and avoid duplication.\n",
    "\n",
    "**Logging DataFrames**\n",
    "\n",
    "`t.log_dataframe(...)` does several things:\n",
    "1. Writes the dataframe to disk (default Parquet)\n",
    "2. Computes a content hash of the file (for cache validation and deduplication)\n",
    "3. Records the file's path as a portable URI (relative to configured mounts)\n",
    "4. Links the artifact to the current run with direction metadata (`input` or `output`)\n",
    "5. Optionally stores additional metadata\n",
    "\n",
    "The returned `Artifact` object wraps the path with provenance information\u2014you can pass it to downstream tasks, and Consist will record the lineage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Optional: No Decorators\n",
    "\n",
    "`@tracker.define_step(...)` is optional. You can also run inline callables and list outputs\n",
    "directly on `run(...)`. That keeps things beginner-friendly while still recording artifacts.\n",
    "\n",
    "```python\n",
    "def simulate_once(*, base_config, sim_cfg):\n",
    "    series_df = run_one_simulation(base_config=base_config, registry_row=sim_cfg)\n",
    "    return consist.log_dataframe(series_df, key=\"sim_series\")\n",
    "\n",
    "scenario.run(\n",
    "    name=\"sim_0001\",\n",
    "    fn=simulate_once,\n",
    "    config={**asdict(base_config), **sim_cfg},\n",
    "    outputs=[\"sim_series\"],\n",
    "    fn_args={\"base_config\": base_config, \"sim_cfg\": sim_cfg},\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "### Two execution patterns\n",
    "\n",
    "In this notebook we show both styles:\n",
    "\n",
    "- **`run(...)` with a reusable step function** (great when you want shared metadata or\n",
    "  a named function for reuse).\n",
    "- **`trace(...)` with inline code** (no wrapper needed; useful for one-off steps).\n",
    "\n",
    "If you already have a library function that *logs outputs itself* using Consist\n",
    "(e.g., it calls `consist.log_dataframe` internally), you can pass that function\n",
    "directly to `run(...)` without a wrapper.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee63d695",
   "metadata": {},
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "\n",
    "@tracker.define_step(outputs=[\"sim_series\"], tags=[\"sim\"])\n",
    "def simulate_run(*, base_config, sim_cfg):\n",
    "    series_df = run_one_simulation(\n",
    "        base_config=base_config,\n",
    "        registry_row=sim_cfg,\n",
    "    )\n",
    "    return consist.log_dataframe(\n",
    "        series_df,\n",
    "        key=\"sim_series\",\n",
    "    )\n",
    "\n",
    "\n",
    "scenario_id = \"predator_prey_sweep\"\n",
    "\n",
    "sample_series_artifact = None\n",
    "\n",
    "with tracker.scenario(\n",
    "    scenario_id,\n",
    "    config={\n",
    "        \"base\": asdict(base_config),\n",
    "        \"sweep\": {\n",
    "            \"prey_birth_rates\": sorted(registry[\"prey_birth_rate\"].unique().tolist()),\n",
    "            \"predation_rates\": sorted(registry[\"predation_rate\"].unique().tolist()),\n",
    "            \"predator_death_rates\": sorted(\n",
    "                registry[\"predator_death_rate\"].unique().tolist()\n",
    "            ),\n",
    "            \"replicates_per_setting\": int(registry[\"replicate_id\"].max() + 1),\n",
    "        },\n",
    "    },\n",
    "    tags=[\"examples\", \"simulation\", \"predator_prey\"],\n",
    ") as scenario:\n",
    "    for row in tqdm(registry.to_dict(orient=\"records\"), total=len(registry)):\n",
    "        sim_cfg = dict(row)\n",
    "        sim_id = int(sim_cfg[\"sim_id\"])\n",
    "\n",
    "        run_id = make_run_id(scenario_id=scenario_id, sim_id=sim_id)\n",
    "        run_config = {\n",
    "            **{\n",
    "                \"steps\": base_config.steps,\n",
    "                \"dt\": base_config.dt,\n",
    "                \"prey_init\": base_config.prey_init,\n",
    "                \"predator_init\": base_config.predator_init,\n",
    "            },\n",
    "            **sim_cfg,\n",
    "        }\n",
    "\n",
    "        if sim_id == 0:\n",
    "            # Inline trace for a single step (no wrapper needed).\n",
    "            with scenario.trace(\n",
    "                name=f\"sim_{sim_id:04d}\",\n",
    "                run_id=run_id,\n",
    "                model=\"simulate\",\n",
    "                config=run_config,\n",
    "                facet_from=[\n",
    "                    \"sim_id\",\n",
    "                    \"setting_id\",\n",
    "                    \"replicate_id\",\n",
    "                    \"prey_birth_rate\",\n",
    "                    \"predation_rate\",\n",
    "                    \"predator_death_rate\",\n",
    "                ],\n",
    "            ):\n",
    "                series_df = run_one_simulation(\n",
    "                    base_config=base_config,\n",
    "                    registry_row=sim_cfg,\n",
    "                )\n",
    "                consist.log_dataframe(series_df, key=\"sim_series\")\n",
    "\n",
    "            if sample_series_artifact is None:\n",
    "                sample_series_artifact = scenario.coupler.require(\"sim_series\")\n",
    "            continue\n",
    "\n",
    "        result = scenario.run(\n",
    "            name=f\"sim_{sim_id:04d}\",\n",
    "            fn=simulate_run,\n",
    "            run_id=run_id,\n",
    "            model=\"simulate\",\n",
    "            config=run_config,\n",
    "            facet_from=[\n",
    "                \"sim_id\",\n",
    "                \"setting_id\",\n",
    "                \"replicate_id\",\n",
    "                \"prey_birth_rate\",\n",
    "                \"predation_rate\",\n",
    "                \"predator_death_rate\",\n",
    "            ],\n",
    "            fn_args={\n",
    "                \"base_config\": base_config,\n",
    "                \"sim_cfg\": sim_cfg,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        if sample_series_artifact is None and result.outputs:\n",
    "            sample_series_artifact = result.outputs[\"sim_series\"]\n",
    "\n",
    "assert sample_series_artifact is not None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a3f9f12d",
   "metadata": {},
   "source": [
    "## 4) Schema Export: From Data to Typed Queries\n",
    "\n",
    "One challenge with scientific workflows is that output schemas evolve organically. You add a column here, rename one there, and soon you're not sure what's in each artifact. Consist can **inspect ingested data and generate SQLModel class definitions**, giving you:\n",
    "\n",
    "1. **Type safety**: Catch column name typos at query-construction time, not runtime\n",
    "2. **IDE support**: Autocomplete for column names in your editor\n",
    "3. **Documentation**: The schema serves as a contract for what the artifact contains\n",
    "4. **Validation**: SQLModel/Pydantic can validate data on read\n",
    "\n",
    "### The Export Workflow\n",
    "\n",
    "1. **Ingest** a sample artifact into DuckDB (Consist inspects its schema)\n",
    "2. **Export** a SQLModel stub with inferred column types\n",
    "3. **Refine** the stub: add primary keys, documentation, semantic types\n",
    "4. **Register** the schema with the Tracker for view creation\n",
    "\n",
    "The generated stub is a starting point\u2014you'll typically want to add constraints and documentation. Here's what the auto-generated vs. refined schemas might look like:\n",
    "\n",
    "```python\n",
    "# Auto-generated (what export_schema_sqlmodel produces)\n",
    "class PredatorPreySeriesGenerated(SQLModel, table=True):\n",
    "    t: int\n",
    "    prey: int\n",
    "    predator: int\n",
    "\n",
    "# Refined (what you'd check into version control)\n",
    "class PredatorPreySeriesChecked(SQLModel, table=True):\n",
    "    \"\"\"Time series output from a single predator-prey simulation.\"\"\"\n",
    "    __tablename__ = \"sim_series\"\n",
    "\n",
    "    t: int = Field(primary_key=True, description=\"Simulation timestep\")\n",
    "    prey: int = Field(ge=0, description=\"Prey population count\")\n",
    "    predator: int = Field(ge=0, description=\"Predator population count\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "afa8e927",
   "metadata": {},
   "source": [
    "from checked_models import PredatorPreySeriesChecked\n",
    "\n",
    "tracker.ingest(sample_series_artifact)\n",
    "\n",
    "tracker.export_schema_sqlmodel(\n",
    "    artifact_id=sample_series_artifact.id,\n",
    "    # out_path=EXAMPLES_SRC / \"generated\" / \"predator_prey_series_preview.py\", # You can also save the model definition to a file path\n",
    "    class_name=\"PredatorPreySeriesGenerated\",\n",
    "    table_name=\"sim_series\",\n",
    ")\n",
    "\n",
    "print(\"Checked-in model:\", PredatorPreySeriesChecked.__name__)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db864144",
   "metadata": {},
   "source": [
    "## 5) Querying Across Runs with Hybrid Views\n\nWith 90 simulations producing time-series data, we want to compute summary statistics (extinction rates, peak populations) across the entire sweep. Consist's **hybrid views** make this possible without:\n\n- Loading all data into memory at once\n- Writing raw SQL strings (we use typed SQLModel/SQLAlchemy expressions)\n- Manually tracking which files correspond to which parameter settings\n\n### How Hybrid Views Work\n\nConsist maintains two data tiers:\n\n| Tier | Storage | Query Speed | When to Use |\n|------|---------|-------------|-------------|\n| **Hot** | Rows in DuckDB tables | Fast (indexed) | Frequently queried data, small-to-medium artifacts |\n| **Cold** | Parquet files on disk | Moderate (file scan) | Large artifacts, archival data |\n\nA **hybrid view** unions both tiers transparently. DuckDB's Parquet reader handles cold data efficiently\u2014you get the convenience of SQL without loading everything into Python.\n\nIn this notebook, we ingested one artifact (for schema inference), so we have:\n- 1 run's data in the hot tier (DuckDB table)\n- 89 runs' data in the cold tier (Parquet files)\n\nBut the query doesn't care\u2014it treats all 90 runs identically.\n\n### Building the Query\n\nWe construct the aggregation in three stages:\n\n**Stage 1: Pivot facets into a queryable table**\n\n`pivot_facets(...)` extracts the key-value pairs we stored in facets (via `facet=` or `facet_from=`) and pivots them into columns:\n\nrun_id\tprey_birth_rate\tpredation_rate\tpredator_death_rate\nrun_001\t0.60\t0.008\t0.15\nrun_002\t0.60\t0.008\t0.15\n...\nvbnet\nCopy code\n\n**Stage 2: Roll up each run's time series**\n\nFor each run, we compute summary statistics from its time series:\n- Peak populations (max prey, max predator)\n- Final populations (value at last timestep)\n- Minimum populations (to detect extinctions)\n\n**Stage 3: Join and aggregate across replicates**\n\nFinally, we join the parameters with the rollup metrics and aggregate across the 10 replicates per setting to compute mean final populations, extinction rates, etc.\n\n---\n\nLet's build this query step by step:"
   ]
  },
  {
   "cell_type": "code",
   "id": "81efc0a2",
   "metadata": {},
   "source": [
    "from sqlalchemy import case, func\n",
    "from sqlmodel import select\n",
    "\n",
    "from checked_models import PredatorPreySeriesChecked, PredatorPreySeriesHot\n",
    "\n",
    "tracker.views.register(PredatorPreySeriesChecked, key=\"sim_series\")\n",
    "\n",
    "SeriesView = tracker.views.PredatorPreySeriesChecked\n",
    "\n",
    "hot_count = run_query(\n",
    "    select(func.count()).select_from(PredatorPreySeriesHot), tracker=tracker\n",
    ")[0]\n",
    "view_count = run_query(select(func.count()).select_from(SeriesView), tracker=tracker)[0]\n",
    "\n",
    "display(pd.DataFrame({\"rows\": [hot_count]}, index=[\"hot_table\"]))\n",
    "display(pd.DataFrame({\"rows\": [view_count]}, index=[\"hybrid_view\"]))\n",
    "\n",
    "params_stmt = pivot_facets(\n",
    "    namespace=\"simulate\",\n",
    "    keys=[\"prey_birth_rate\", \"predation_rate\", \"predator_death_rate\"],\n",
    ")\n",
    "\n",
    "series_rollup = (\n",
    "    select(\n",
    "        SeriesView.consist_run_id.label(\"run_id\"),\n",
    "        func.max(SeriesView.prey).label(\"prey_peak\"),\n",
    "        func.max(SeriesView.predator).label(\"predator_peak\"),\n",
    "        func.arg_max(SeriesView.prey, SeriesView.t).label(\"prey_final\"),\n",
    "        func.arg_max(SeriesView.predator, SeriesView.t).label(\"predator_final\"),\n",
    "        func.min(SeriesView.prey).label(\"prey_min\"),\n",
    "        func.min(SeriesView.predator).label(\"predator_min\"),\n",
    "    )\n",
    "    .group_by(SeriesView.consist_run_id)\n",
    "    .subquery()\n",
    ")\n",
    "\n",
    "summary_stmt = (\n",
    "    select(\n",
    "        params_stmt.c.prey_birth_rate,\n",
    "        params_stmt.c.predation_rate,\n",
    "        params_stmt.c.predator_death_rate,\n",
    "        func.count().label(\"sims\"),\n",
    "        func.avg(case((series_rollup.c.prey_min == 0, 1), else_=0)).label(\n",
    "            \"prey_extinct_rate\"\n",
    "        ),\n",
    "        func.avg(case((series_rollup.c.predator_min == 0, 1), else_=0)).label(\n",
    "            \"predator_extinct_rate\"\n",
    "        ),\n",
    "        func.avg(series_rollup.c.prey_final).label(\"mean_prey_final\"),\n",
    "        func.avg(series_rollup.c.predator_final).label(\"mean_predator_final\"),\n",
    "        func.avg(series_rollup.c.prey_peak).label(\"mean_prey_peak\"),\n",
    "        func.avg(series_rollup.c.predator_peak).label(\"mean_predator_peak\"),\n",
    "    )\n",
    "    .join(series_rollup, series_rollup.c.run_id == params_stmt.c.run_id)\n",
    "    .group_by(\n",
    "        params_stmt.c.prey_birth_rate,\n",
    "        params_stmt.c.predation_rate,\n",
    "        params_stmt.c.predator_death_rate,\n",
    "    )\n",
    ")\n",
    "\n",
    "summary_rows = run_query(summary_stmt, tracker=tracker)\n",
    "summary_df = pd.DataFrame([row._mapping for row in summary_rows])\n",
    "\n",
    "summary_path = artifact_root / \"sweep_summary.parquet\"\n",
    "write_parquet(summary_df, summary_path)\n",
    "\n",
    "summary_df.sort_values(\n",
    "    [\"predator_extinct_rate\", \"prey_extinct_rate\"], ascending=False\n",
    ").head(8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "745d2478",
   "metadata": {},
   "source": [
    "## 6) Interpreting the Results\n",
    "\n",
    "The heatmap reveals the **transition region** between coexistence and extinction. At low predation rates (left column), predators can't catch enough prey to sustain themselves. At high predation rates (right column), predators over-exploit prey, causing boom-bust cycles that often end in extinction.\n",
    "\n",
    "The interesting dynamics happen in the middle\u2014where stochastic fluctuations determine whether the system settles into stable coexistence or tips into extinction.\n",
    "\n",
    "### The Provenance Payoff\n",
    "\n",
    "Notice what we *didn't* do:\n",
    "- Parse filenames to extract parameter values\n",
    "- Maintain a spreadsheet mapping run IDs to configurations\n",
    "- Write custom aggregation code that loops over files\n",
    "\n",
    "Instead, we derived this heatmap from 90 simulations using a single SQL query against Consist's provenance database. If we later want to drill into a specific run (say, one where predators went extinct unusually early), we can trace back to the exact configuration and artifacts that produced it."
   ]
  },
  {
   "cell_type": "code",
   "id": "57fcf003",
   "metadata": {},
   "source": [
    "summary_df = pd.read_parquet(artifact_root / \"sweep_summary.parquet\")\n",
    "\n",
    "# Example: visualize extinction risk as a heatmap (fix death rate to one slice)\n",
    "death_rate = float(sorted(summary_df[\"predator_death_rate\"].unique())[0])\n",
    "slice_df = summary_df[summary_df[\"predator_death_rate\"] == death_rate]\n",
    "pivot = slice_df.pivot_table(\n",
    "    index=\"prey_birth_rate\",\n",
    "    columns=\"predation_rate\",\n",
    "    values=\"predator_extinct_rate\",\n",
    ")\n",
    "\n",
    "ax = sns.heatmap(pivot.sort_index(), annot=True, fmt=\".2f\", cmap=\"mako\", vmin=0, vmax=1)\n",
    "ax.set_title(f\"Predator extinction rate (predator_death_rate={death_rate})\")\n",
    "ax.set_xlabel(\"predation_rate\")\n",
    "ax.set_ylabel(\"prey_birth_rate\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "acb24bf9-c18a-40b4-bb5f-9e07326316fb",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "544f2a47",
   "metadata": {},
   "source": [
    "## 7) What's in the Database?\n",
    "\n",
    "Consist stores provenance in DuckDB, which you can inspect directly. The key tables are:\n",
    "\n",
    "| Table | Purpose |\n",
    "|-------|---------|\n",
    "| `run` | One row per execution: config hash, timestamps, status, parent linkage |\n",
    "| `artifact` | File registry: paths (as portable URIs), content hashes, schemas |\n",
    "| `run_artifact_link` | Many-to-many: which artifacts are inputs/outputs of which runs |\n",
    "| `config_facet` | Deduplicated facet JSON blobs (content-addressed) |\n",
    "| `run_config_kv` | Flattened key-value index for efficient facet filtering |\n",
    "\n",
    "The `global_tables` schema contains **ingested artifact data** (our hot tier). Views like `v_sim_series` provide the hybrid interface.\n",
    "\n",
    "### Portability\n",
    "\n",
    "Because Consist stores:\n",
    "- **Relative URIs** (not absolute paths)\n",
    "- **Content hashes** (not just filenames)\n",
    "- **Portable run metadata** (JSON snapshots in each run directory)\n",
    "\n",
    "You can:\n",
    "- Move the `runs/` directory to a different machine\n",
    "- Share the `.duckdb` file with collaborators (after adjusting mount paths)\n",
    "- Rebuild the database from JSON snapshots if it gets corrupted\n",
    "\n",
    "> **Explore interactively**: DuckDB has a built-in UI. Run `duckdb -ui {path}` in your terminal to browse tables, run ad-hoc queries, and visualize the provenance graph."
   ]
  },
  {
   "cell_type": "code",
   "id": "18babc08",
   "metadata": {},
   "source": [
    "from sqlalchemy import inspect\n",
    "from sqlmodel import select\n",
    "\n",
    "from consist.models import Artifact, ConfigFacet, Run, RunConfigKV\n",
    "\n",
    "inspector = inspect(tracker.engine)\n",
    "main_tables = inspector.get_table_names()\n",
    "global_tables = inspector.get_table_names(schema=\"global_tables\")\n",
    "views = inspector.get_view_names()\n",
    "\n",
    "display(pd.DataFrame({\"main_tables\": main_tables}))\n",
    "display(pd.DataFrame({\"global_tables\": global_tables}))\n",
    "display(pd.DataFrame({\"views\": views}))\n",
    "\n",
    "table_counts = {\n",
    "    \"run\": run_query(select(func.count()).select_from(Run), tracker=tracker)[0],\n",
    "    \"artifact\": run_query(select(func.count()).select_from(Artifact), tracker=tracker)[\n",
    "        0\n",
    "    ],\n",
    "    \"config_facet\": run_query(\n",
    "        select(func.count()).select_from(ConfigFacet), tracker=tracker\n",
    "    )[0],\n",
    "    \"run_config_kv\": run_query(\n",
    "        select(func.count()).select_from(RunConfigKV), tracker=tracker\n",
    "    )[0],\n",
    "}\n",
    "display(pd.DataFrame({\"rows\": table_counts}))\n",
    "\n",
    "print(f\"DuckDB file: {DB_PATH}\")\n",
    "print(f\"Open UI in a terminal: duckdb -ui {DB_PATH}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a316e0e-fa2b-42c8-af9a-2224ebe27eec",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}